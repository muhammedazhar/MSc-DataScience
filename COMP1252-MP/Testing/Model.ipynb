{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Essential imports\n",
    "    import re\n",
    "    import os\n",
    "    import sys\n",
    "    import json\n",
    "    import glob\n",
    "    import torch\n",
    "    import shutil\n",
    "    import random\n",
    "    import torch.nn as nn\n",
    "    import logging\n",
    "    import rasterio\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    import geopandas as gpd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from PIL import Image\n",
    "    from datetime import datetime\n",
    "    from pathlib import Path\n",
    "    from scipy import stats\n",
    "    from typing import Dict, Tuple, Optional\n",
    "    from collections import defaultdict\n",
    "    from rasterio import plot\n",
    "    from rasterio.mask import mask\n",
    "    from shapely.ops import unary_union\n",
    "    from shapely.wkt import dumps, loads\n",
    "    from shapely.geometry import mapping, box, Polygon, MultiPolygon\n",
    "    from rasterio.windows import from_bounds, bounds as window_bounds\n",
    "    from s2cloudless import S2PixelCloudDetector\n",
    "    from tqdm import tqdm\n",
    "    from tqdm.notebook import tqdm\n",
    "    from sklearn.model_selection import TimeSeriesSplit\n",
    "except Exception as e:\n",
    "    print(f\"Error : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0.dev20241112\n",
      "Is Apple MPS (Metal Performance Shader) built? True\n",
      "Is Apple MPS available? True\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Print the PyTorch version\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check if running in Google Colab\n",
    "if \"google.colab\" in str(get_ipython()):\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "        print(\"GPU not available in Colab, consider enabling a GPU runtime.\")\n",
    "# Running on a local machine\n",
    "else:\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = 'mps'\n",
    "        print(f\"Is Apple MPS (Metal Performance Shader) built? {torch.backends.mps.is_built()}\")\n",
    "        print(f\"Is Apple MPS available? {torch.backends.mps.is_available()}\")\n",
    "    elif torch.cuda.is_available():\n",
    "        device = 'cuda'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "\n",
    "# TODO: Add support for AMD ROCm GPU if needed\n",
    "\n",
    "# Print the device being used\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNetDiff(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # ResNet-18 backbone\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        \n",
    "        # Encoder (modified ResNet-18)\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv2d(27, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            resnet.bn1,\n",
    "            resnet.relu\n",
    "        )\n",
    "        self.pool = resnet.maxpool\n",
    "        self.encoder2 = resnet.layer1\n",
    "        self.encoder3 = resnet.layer2\n",
    "        \n",
    "        # Decoder\n",
    "        self.upconv3 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.decoder3 = ConvBlock(128, 64)\n",
    "        \n",
    "        self.upconv2 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
    "        self.decoder2 = ConvBlock(96, 32)\n",
    "        \n",
    "        self.upconv1 = nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2)\n",
    "        self.decoder1 = ConvBlock(80, 16)\n",
    "        \n",
    "        self.final_conv = nn.Conv2d(16, 1, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1 = self.encoder1(x)  # 64 channels\n",
    "        pool1 = self.pool(enc1)\n",
    "        \n",
    "        enc2 = self.encoder2(pool1)  # 64 channels\n",
    "        enc3 = self.encoder3(enc2)  # 128 channels\n",
    "        \n",
    "        # Decoder with skip connections\n",
    "        dec3 = self.upconv3(enc3)\n",
    "        dec3 = torch.cat([dec3, enc2], dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        \n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat([dec2, enc1], dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        \n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat([dec1, x], dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "        \n",
    "        # Final 1x1 convolution\n",
    "        out = self.final_conv(dec1)\n",
    "        return torch.sigmoid(out)\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-6):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "        \n",
    "    def forward(self, predictions, targets):\n",
    "        predictions = predictions.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (predictions * targets).sum()\n",
    "        dice = (2.0 * intersection + self.smooth) / (\n",
    "            predictions.sum() + targets.sum() + self.smooth\n",
    "        )\n",
    "        return 1 - dice\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, bce_weight=0.2, dice_weight=0.8):\n",
    "        super().__init__()\n",
    "        self.bce_loss = nn.BCELoss()\n",
    "        self.dice_loss = DiceLoss()\n",
    "        self.bce_weight = bce_weight\n",
    "        self.dice_weight = dice_weight\n",
    "        \n",
    "    def forward(self, predictions, targets):\n",
    "        bce = self.bce_loss(predictions, targets)\n",
    "        dice = self.dice_loss(predictions, targets)\n",
    "        return self.bce_weight * bce + self.dice_weight * dice\n",
    "\n",
    "def create_optimizer_and_scheduler(model):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "        optimizer,\n",
    "        milestones=[10, 40, 80, 150],\n",
    "        gamma=0.1\n",
    "    )\n",
    "    \n",
    "    return optimizer, scheduler\n",
    "\n",
    "import albumentations as A\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Define augmentations\n",
    "train_transform = A.Compose([\n",
    "    A.RandomCrop(int(224 * 0.7), int(224 * 0.7)),\n",
    "    A.Resize(224, 224),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.ElasticTransform(p=0.5),\n",
    "    A.GridDistortion(p=0.5),\n",
    "    A.CoarseDropout(max_holes=8, max_height=20, max_width=20, p=0.5)\n",
    "])\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=200):\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = CombinedLoss()\n",
    "    optimizer, scheduler = create_optimizer_and_scheduler(model)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                val_loss += criterion(output, target).item()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # Print epoch results\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'Training Loss: {train_loss:.4f}')\n",
    "        print(f'Validation Loss: {val_loss:.4f}')\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_unet_diff.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "\n",
    "class TemporalStackDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, split='train'):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.transform = transform\n",
    "        self.split = split\n",
    "        \n",
    "        # Get all plot directories\n",
    "        plot_dirs = sorted([d for d in self.root_dir.iterdir() if d.is_dir()])\n",
    "        \n",
    "        # Split train/val\n",
    "        split_idx = int(0.8 * len(plot_dirs))\n",
    "        self.plot_dirs = plot_dirs[:split_idx] if split == 'train' else plot_dirs[split_idx:]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.plot_dirs)\n",
    "    \n",
    "    def load_temporal_stack(self, stack_dir):\n",
    "        npy_files = sorted(list(stack_dir.glob('*.npy')))\n",
    "        if not npy_files:\n",
    "            raise ValueError(f\"No .npy files found in {stack_dir}\")\n",
    "        return np.concatenate([np.load(f) for f in npy_files], axis=-1)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        plot_dir = self.plot_dirs[idx]\n",
    "        \n",
    "        # Load stacks\n",
    "        pre_event_dir = plot_dir / 'Pre-event'\n",
    "        post_event_dir = plot_dir / 'Post-event'\n",
    "        \n",
    "        try:\n",
    "            pre_stack = self.load_temporal_stack(pre_event_dir)\n",
    "            post_stack = self.load_temporal_stack(post_event_dir)\n",
    "            \n",
    "            # Concatenate pre and post stacks\n",
    "            x = np.concatenate([pre_stack, post_stack], axis=-1)\n",
    "            \n",
    "            # Create dummy mask if needed\n",
    "            mask = np.zeros((224, 224, 1), dtype=np.float32)\n",
    "            \n",
    "            if self.transform:\n",
    "                transformed = self.transform(image=x, mask=mask)\n",
    "                x = transformed['image']\n",
    "                mask = transformed['mask']\n",
    "            \n",
    "            # Convert to torch tensors\n",
    "            x = torch.from_numpy(x).float().permute(2, 0, 1)\n",
    "            mask = torch.from_numpy(mask).float()\n",
    "            \n",
    "            return x, mask\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data from {plot_dir}: {str(e)}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inspecting PLOT-00026\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00019\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00021\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00017\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00028\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00044\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00043\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00011\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00016\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00029\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00020\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00027\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00042\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00045\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00058\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00060\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00056\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00005\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00002\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00034\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00033\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00050\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00057\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00061\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00066\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00059\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00032\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00035\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00003\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00004\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00040\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00047\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00025\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00014\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00048\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00046\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00041\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00015\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00012\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00024\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00023\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00001\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00039\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00006\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00030\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00008\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00037\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00063\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00064\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00052\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00055\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00009\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00036\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00038\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00007\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00054\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00053\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00065\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n",
      "\n",
      "Inspecting PLOT-00062\n",
      "Pre-event shape: (9, 224, 224)\n",
      "Post-event shape: (9, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "def inspect_data_shapes(root_dir):\n",
    "    root = Path(root_dir)\n",
    "    for plot_dir in root.glob('PLOT-*'):\n",
    "        print(f\"\\nInspecting {plot_dir.name}\")\n",
    "        \n",
    "        # Check pre-event\n",
    "        pre_dir = plot_dir / 'Pre-event'\n",
    "        pre_files = list(pre_dir.glob('*.npy'))\n",
    "        if pre_files:\n",
    "            pre_shape = np.load(pre_files[0]).shape\n",
    "            print(f\"Pre-event shape: {pre_shape}\")\n",
    "            \n",
    "        # Check post-event    \n",
    "        post_dir = plot_dir / 'Post-event'\n",
    "        post_files = list(post_dir.glob('*.npy'))\n",
    "        if post_files:\n",
    "            post_shape = np.load(post_files[0]).shape\n",
    "            print(f\"Post-event shape: {post_shape}\")\n",
    "\n",
    "# Run inspection\n",
    "inspect_data_shapes('../Datasets/Testing/TemporalStacks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading data from ../Datasets/Testing/TemporalStacks/PLOT-00015: No .npy files found in ../Datasets/Testing/TemporalStacks/PLOT-00015/Pre-event\n",
      "Error loading test batch: No .npy files found in ../Datasets/Testing/TemporalStacks/PLOT-00015/Pre-event\n"
     ]
    }
   ],
   "source": [
    "# from dataset import TemporalStackDataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Initialize datasets with fewer workers for debugging\n",
    "train_dataset = TemporalStackDataset(\n",
    "    root_dir='../Datasets/Testing/TemporalStacks',\n",
    "    transform=train_transform,\n",
    "    split='train'\n",
    ")\n",
    "\n",
    "val_dataset = TemporalStackDataset(\n",
    "    root_dir='../Datasets/Testing/TemporalStacks',\n",
    "    transform=None,\n",
    "    split='val'\n",
    ")\n",
    "\n",
    "# Create data loaders with fewer workers\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=0  # Start with 0 for debugging\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    num_workers=0  # Start with 0 for debugging\n",
    ")\n",
    "\n",
    "# Test loading one batch\n",
    "try:\n",
    "    test_batch = next(iter(train_loader))\n",
    "    print(\"Test batch shape:\", test_batch[0].shape)\n",
    "except Exception as e:\n",
    "    print(\"Error loading test batch:\", str(e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COMP1252-MP(GPU)",
   "language": "python",
   "name": "comp1252-mp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
