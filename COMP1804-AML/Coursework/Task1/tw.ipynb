{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "         par_id                                          paragraph  \\\n",
      "0  428209002237  Ramsay was born in Glasgow on 2 October 1852. ...   \n",
      "1  564218010072  It has been widely estimated for at least the ...   \n",
      "2  291401001672  He went on to win the Royal Medal of the Royal...   \n",
      "3   31548004883  The changes have altered many underlying assum...   \n",
      "4   50634005146  After these novels were published, Disraeli de...   \n",
      "\n",
      "                        has_entity  lexicon_count  difficult_words  \\\n",
      "0   ORG_YES_PRODUCT_NO_PERSON_YES_             49             12.0   \n",
      "1    ORG_YES_PRODUCT_NO_PERSON_NO_            166             47.0   \n",
      "2    ORG_YES_PRODUCT_NO_PERSON_NO_             69             18.0   \n",
      "3    ORG_NO_PRODUCT_YES_PERSON_NO_             76             27.0   \n",
      "4  ORG_YES_PRODUCT_YES_PERSON_YES_            200             47.0   \n",
      "\n",
      "  last_editor_gender                 category      text_clarity  \n",
      "0                man              biographies      clear_enough  \n",
      "1                man  artificial intelligence  not_clear_enough  \n",
      "2         non-binary              biographies      clear_enough  \n",
      "3         non-binary              programming      clear_enough  \n",
      "4                man              biographies  not_clear_enough  \n",
      "             par_id  lexicon_count  difficult_words\n",
      "count  9.347000e+03    9347.000000      9329.000000\n",
      "mean   3.568369e+11      81.981277        21.514203\n",
      "std    3.221399e+11      63.533532        16.307358\n",
      "min    8.500328e+07       0.000000         0.000000\n",
      "25%    7.019601e+10      33.000000         9.000000\n",
      "50%    2.684380e+11      64.000000        17.000000\n",
      "75%    6.124310e+11     117.000000        30.000000\n",
      "max    1.058779e+12     653.000000       143.000000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9347 entries, 0 to 9346\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   par_id              9347 non-null   int64  \n",
      " 1   paragraph           9347 non-null   object \n",
      " 2   has_entity          9347 non-null   object \n",
      " 3   lexicon_count       9347 non-null   int64  \n",
      " 4   difficult_words     9329 non-null   float64\n",
      " 5   last_editor_gender  9347 non-null   object \n",
      " 6   category            9286 non-null   object \n",
      " 7   text_clarity        9 non-null      object \n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 584.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(df.head())\n",
    "\n",
    "# Display summary statistics and information about the dataset\n",
    "print(df.describe())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muhammedazhar\\AppData\\Local\\Temp\\ipykernel_22260\\1679241535.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['difficult_words'].fillna(df['difficult_words'].mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing completed. Data is ready for model training.\n"
     ]
    }
   ],
   "source": [
    "# Fill in missing 'difficult_words' values with the column's mean\n",
    "df['difficult_words'].fillna(df['difficult_words'].mean(), inplace=True)\n",
    "\n",
    "# Drop rows where 'category' is missing\n",
    "df.dropna(subset=['category'], inplace=True)\n",
    "\n",
    "# Extract binary features from 'has_entity'\n",
    "df['has_product'] = df['has_entity'].apply(lambda x: 1 if 'PRODUCT_YES' in x else 0)\n",
    "df['has_organization'] = df['has_entity'].apply(lambda x: 1 if 'ORG_YES' in x else 0)\n",
    "df['has_person'] = df['has_entity'].apply(lambda x: 1 if 'PERSON_YES' in x else 0)\n",
    "\n",
    "# Now, let's vectorize the 'paragraph' text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "X_tfidf = tfidf.fit_transform(df['paragraph']).toarray()\n",
    "\n",
    "# Incorporate 'has_product', 'has_organization', 'has_person', and 'difficult_words' into our features\n",
    "import numpy as np\n",
    "\n",
    "additional_features = df[['has_product', 'has_organization', 'has_person', 'difficult_words']].to_numpy()\n",
    "X = np.hstack((X_tfidf, additional_features))\n",
    "\n",
    "# Encode the target variable 'category'\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(df['category'])\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Preprocessing completed. Data is ready for model training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[  1   0   0   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0   0]\n",
      " [  0   0   0   0   0   0   0   5   0]\n",
      " [  0   0   0   0   0   1   0   0   1]\n",
      " [  0   0   0   0 205  38   1  31  28]\n",
      " [  0   0   0   0   6 545   0  59  11]\n",
      " [  0   0   0   0   0   5  21   2   2]\n",
      " [  0   0   0   0  17  46   0 421  11]\n",
      " [  0   0   0   0  18  15   0  16 350]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         2\n",
      "           1       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.83      0.68      0.75       303\n",
      "           6       0.84      0.88      0.86       621\n",
      "           7       0.95      0.70      0.81        30\n",
      "           8       0.79      0.85      0.82       495\n",
      "           9       0.87      0.88      0.87       399\n",
      "\n",
      "    accuracy                           0.83      1858\n",
      "   macro avg       0.59      0.50      0.53      1858\n",
      "weighted avg       0.83      0.83      0.83      1858\n",
      "\n",
      "Accuracy Score: 0.8304628632938643\n",
      "Misclassification Rate (Machine Learning Model): 0.16953713670613568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammedazhar\\cuda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\muhammedazhar\\cuda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\muhammedazhar\\cuda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Assuming 'accuracy_score' is the accuracy of your model on the test set\n",
    "misclassification_rate_ml = 1 - accuracy_score(y_test, y_pred)\n",
    "print(f\"Misclassification Rate (Machine Learning Model): {misclassification_rate_ml}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[  1   0   0   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0   0]\n",
      " [  0   0   0   0   0   0   0   5   0]\n",
      " [  0   0   0   0   1   0   0   1   0]\n",
      " [  1   1   1   0 214  35   4  37  10]\n",
      " [  1   1   0   0   6 561   1  43   8]\n",
      " [  0   0   0   0   1   2  27   0   0]\n",
      " [  0   1   1   0  10  54   2 423   4]\n",
      " [  0   0   1   0  12  25   0  34 327]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.50      0.40         2\n",
      "           1       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.87      0.71      0.78       303\n",
      "           6       0.83      0.90      0.86       621\n",
      "           7       0.79      0.90      0.84        30\n",
      "           8       0.78      0.85      0.82       495\n",
      "           9       0.94      0.82      0.87       399\n",
      "\n",
      "    accuracy                           0.84      1858\n",
      "   macro avg       0.50      0.52      0.51      1858\n",
      "weighted avg       0.84      0.84      0.84      1858\n",
      "\n",
      "Accuracy Score: 0.8358449946178687\n",
      "Misclassification Rate (Machine Learning Model): 0.16415500538213135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammedazhar\\cuda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\muhammedazhar\\cuda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\muhammedazhar\\cuda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize the Gradient Boosting Classifier\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_gb = gb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_gb))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_gb))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred_gb))\n",
    "\n",
    "# Assuming 'accuracy_score' is the accuracy of your model on the test set\n",
    "misclassification_rate_ml = 1 - accuracy_score(y_test, y_pred_gb)\n",
    "print(f\"Misclassification Rate (Machine Learning Model): {misclassification_rate_ml}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammedazhar\\cuda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best Score: 0.8131394722670975\n",
      "Accuracy Score of the Best Model: 0.8331539289558665\n",
      "Misclassification Rate (Machine Learning Model): 0.16684607104413351\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Parameters grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "# Initialize Grid Search\n",
    "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
    "                           param_grid=param_grid,\n",
    "                           cv=3,  # Number of cross-validation folds\n",
    "                           verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit Grid Search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the best model found by Grid Search on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "print(\"Accuracy Score of the Best Model:\", accuracy_score(y_test, y_pred_best))\n",
    "# Assuming 'accuracy_score' is the accuracy of your model on the test set\n",
    "misclassification_rate_ml = 1 - accuracy_score(y_test, y_pred_best)\n",
    "print(f\"Misclassification Rate (Machine Learning Model): {misclassification_rate_ml}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_glove_embeddings(path):\n",
    "    embeddings = {}\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings[word] = vector\n",
    "    return embeddings\n",
    "\n",
    "# Assuming you've set the correct path to the GloVe embeddings file\n",
    "glove_embeddings = load_glove_embeddings(r'C:\\Users\\muhammedazhar\\Developer\\MSc-DataScience\\COMP1804-AML\\Coursework\\WordEmbeddings\\glove.6B.100d.txt')\n",
    "print(f\"Loaded {len(glove_embeddings)} word vectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for the first paragraph: [ 0.051743   -0.13768024  0.19746544  0.00786557  0.17483612]...\n"
     ]
    }
   ],
   "source": [
    "def paragraph_to_vector(paragraph, embeddings, dim=100):\n",
    "    words = paragraph.split()\n",
    "    vector = np.zeros(dim)\n",
    "    num_words = 0\n",
    "    for word in words:\n",
    "        if word in embeddings:\n",
    "            vector += embeddings[word]\n",
    "            num_words += 1\n",
    "    if num_words > 0:\n",
    "        vector /= num_words\n",
    "    return vector\n",
    "\n",
    "# Example usage\n",
    "sample_paragraph = df['paragraph'].iloc[0]\n",
    "sample_vector = paragraph_to_vector(sample_paragraph, glove_embeddings)\n",
    "print(f\"Vector for the first paragraph: {sample_vector[:5]}...\")  # Display the first 5 elements for brevity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the transformed feature matrix: (9286, 100)\n"
     ]
    }
   ],
   "source": [
    "# Transform all paragraphs in the dataset into vectors\n",
    "X_embeddings = np.array([paragraph_to_vector(p, glove_embeddings) for p in df['paragraph']])\n",
    "\n",
    "# Display the shape of the new feature matrix to confirm transformation\n",
    "print(\"Shape of the transformed feature matrix:\", X_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[  1   0   0   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0   0]\n",
      " [  0   0   0   0   0   1   0   4   0]\n",
      " [  0   0   0   0   0   0   0   1   1]\n",
      " [  0   0   0   0 203  25   0  32  43]\n",
      " [  0   0   0   0  13 544   0  61   3]\n",
      " [  0   0   0   0   2  18   5   1   4]\n",
      " [  0   0   0   0  26  41   0 413  15]\n",
      " [  0   0   0   0  19  13   0  23 344]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         2\n",
      "           1       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.77      0.67      0.72       303\n",
      "           6       0.85      0.88      0.86       621\n",
      "           7       1.00      0.17      0.29        30\n",
      "           8       0.77      0.83      0.80       495\n",
      "           9       0.84      0.86      0.85       399\n",
      "\n",
      "    accuracy                           0.81      1858\n",
      "   macro avg       0.58      0.43      0.46      1858\n",
      "weighted avg       0.81      0.81      0.81      1858\n",
      "\n",
      "Accuracy Score: 0.8127018299246501\n",
      "Misclassification Rate (Machine Learning Model): 0.18729817007534988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammedazhar\\cuda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\muhammedazhar\\cuda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\muhammedazhar\\cuda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Update the dataset split to use the new embeddings\n",
    "X_train_emb, X_test_emb, y_train_emb, y_test_emb = train_test_split(X_embeddings, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the RandomForestClassifier on the new feature matrix\n",
    "rf_classifier_emb = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier_emb.fit(X_train_emb, y_train_emb)\n",
    "\n",
    "# Predict on the test set and evaluate\n",
    "y_pred_emb = rf_classifier_emb.predict(X_test_emb)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_emb, y_pred_emb))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_emb, y_pred_emb))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test_emb, y_pred_emb))\n",
    "\n",
    "# Assuming 'accuracy_score' is the accuracy of your model on the test set\n",
    "misclassification_rate_ml = 1 - accuracy_score(y_test_emb, y_pred_emb)\n",
    "print(f\"Misclassification Rate (Machine Learning Model): {misclassification_rate_ml}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow vesion: 2.16.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('TensorFlow vesion:', tf.__version__)\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_one_hot = to_categorical(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_nn, X_test_nn, y_train_nn, y_test_nn = train_test_split(X_embeddings, y_one_hot, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammedazhar\\cuda\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m12,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,834</span> (85.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,834\u001b[0m (85.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,834</span> (85.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,834\u001b[0m (85.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Determine the number of features (dimensions of GloVe embeddings)\n",
    "input_dim = X_train_nn.shape[1]  # Should be 100 if using GloVe 100d embeddings\n",
    "# Determine the number of output classes\n",
    "num_classes = y_one_hot.shape[1]\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    Dense(128, input_dim=input_dim, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Display the model's architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "209/209 - 1s - 6ms/step - accuracy: 0.4865 - loss: 1.3547 - val_accuracy: 0.7106 - val_loss: 0.8316\n",
      "Epoch 2/20\n",
      "209/209 - 0s - 1ms/step - accuracy: 0.6811 - loss: 0.9040 - val_accuracy: 0.7456 - val_loss: 0.6867\n",
      "Epoch 3/20\n",
      "209/209 - 0s - 1ms/step - accuracy: 0.7266 - loss: 0.7983 - val_accuracy: 0.7739 - val_loss: 0.6166\n",
      "Epoch 4/20\n",
      "209/209 - 0s - 1ms/step - accuracy: 0.7556 - loss: 0.7350 - val_accuracy: 0.7820 - val_loss: 0.5949\n",
      "Epoch 5/20\n",
      "209/209 - 0s - 1ms/step - accuracy: 0.7617 - loss: 0.7076 - val_accuracy: 0.7847 - val_loss: 0.5730\n",
      "Epoch 6/20\n",
      "209/209 - 0s - 1ms/step - accuracy: 0.7761 - loss: 0.6758 - val_accuracy: 0.7941 - val_loss: 0.5646\n",
      "Epoch 7/20\n",
      "209/209 - 0s - 1ms/step - accuracy: 0.7934 - loss: 0.6557 - val_accuracy: 0.7873 - val_loss: 0.5550\n",
      "Epoch 8/20\n",
      "209/209 - 0s - 1ms/step - accuracy: 0.7949 - loss: 0.6302 - val_accuracy: 0.8062 - val_loss: 0.5389\n",
      "Epoch 9/20\n",
      "209/209 - 0s - 1ms/step - accuracy: 0.7967 - loss: 0.6213 - val_accuracy: 0.8008 - val_loss: 0.5310\n",
      "Epoch 10/20\n",
      "209/209 - 0s - 1ms/step - accuracy: 0.8004 - loss: 0.6060 - val_accuracy: 0.8062 - val_loss: 0.5225\n",
      "Epoch 11/20\n",
      "209/209 - 0s - 1ms/step - accuracy: 0.8025 - loss: 0.6028 - val_accuracy: 0.8129 - val_loss: 0.5125\n",
      "Epoch 12/20\n",
      "209/209 - 0s - 1ms/step - accuracy: 0.8070 - loss: 0.5870 - val_accuracy: 0.8129 - val_loss: 0.5174\n",
      "Epoch 13/20\n",
      "209/209 - 0s - 1ms/step - accuracy: 0.8106 - loss: 0.5872 - val_accuracy: 0.8102 - val_loss: 0.5353\n",
      "Epoch 14/20\n",
      "209/209 - 0s - 1ms/step - accuracy: 0.8094 - loss: 0.5839 - val_accuracy: 0.8170 - val_loss: 0.5059\n",
      "Epoch 15/20\n",
      "209/209 - 0s - 1ms/step - accuracy: 0.8153 - loss: 0.5748 - val_accuracy: 0.8156 - val_loss: 0.5221\n",
      "Epoch 16/20\n",
      "209/209 - 0s - 1ms/step - accuracy: 0.8271 - loss: 0.5578 - val_accuracy: 0.8170 - val_loss: 0.5043\n",
      "Epoch 17/20\n",
      "209/209 - 0s - 1ms/step - accuracy: 0.8212 - loss: 0.5601 - val_accuracy: 0.8304 - val_loss: 0.5021\n",
      "Epoch 18/20\n",
      "209/209 - 0s - 1ms/step - accuracy: 0.8250 - loss: 0.5493 - val_accuracy: 0.8183 - val_loss: 0.4981\n",
      "Epoch 19/20\n",
      "209/209 - 0s - 1ms/step - accuracy: 0.8247 - loss: 0.5402 - val_accuracy: 0.8345 - val_loss: 0.4895\n",
      "Epoch 20/20\n",
      "209/209 - 0s - 1ms/step - accuracy: 0.8208 - loss: 0.5539 - val_accuracy: 0.8223 - val_loss: 0.5049\n",
      "59/59 - 0s - 904us/step - accuracy: 0.8337 - loss: 0.4720\n",
      "Test Loss: 0.47199317812919617\n",
      "Test Accuracy: 0.8336921334266663\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train_nn, y_train_nn,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.1,\n",
    "                    verbose=2)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test_nn, y_test_nn, verbose=2)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">25,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m25,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69,194</span> (270.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m69,194\u001b[0m (270.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">68,426</span> (267.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m68,426\u001b[0m (267.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "\n",
    "# Adjust the model architecture\n",
    "model = Sequential([\n",
    "    Dense(256, input_dim=input_dim, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model with potentially adjusted learning rate\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Display the adjusted model's architecture\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COMP1804-AML(GPU)",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
