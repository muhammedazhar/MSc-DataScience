{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLTmRhhGjULD"
   },
   "source": [
    "# COMP1801 Tutorial Week 6 - Neural Networks\n",
    "*Dr Peter Soar - 2024/25*\n",
    "$\\newcommand{\\Vec}[1]{\\boldsymbol{#1}}$\n",
    "$\\newcommand{\\Mat}[1]{\\boldsymbol{#1}}$\n",
    "\n",
    "This tutorial should be pulling together everything we have been learning so far in supervised learning. Neural Networks can be applied to both Regression and Classification problems to create complex deep learning models which if constructed and trained correctly should generally outperform any traditional linear models we've been dealing with so far. This tutorial should show you how to implement a general neural network using `tensorflow.keras` by combining different types of layers.\n",
    "\n",
    "For this tutorial, read through and try to understand the text and code examples I have provided (ask your tutor if you have any questions) and there will be a selection of exercises. Attempt these exercises on your own, but do ask your tutor for help if you get stuck.\n",
    "\n",
    "### Note: It is strongly advised to USE **GOOGLE COLAB** (not offline environments) when using Tensorflow.\n",
    "\n",
    "*   Tensorflow enables you to leverage relatively powerful GPUs.\n",
    "*   Running Tensorflow to your laptop/PC can be difficult to set up and may cause technical problems during training.\n",
    "*   In Colab **Ensure runtime is changed to GPU** to accelerate execution speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSo3PZoZeF3M"
   },
   "source": [
    "#0. Do not forget to import all the Python Libraries being used!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AIhPMWKy2ML2"
   },
   "outputs": [],
   "source": [
    "import numpy as np # A useful package for dealing with mathematical processes, we will be using it this week for vectors and matrices.\n",
    "import pandas as pd # A common package for viewing tabular data\n",
    "import sklearn.datasets # We want to be able to access the sklearn datasets again\n",
    "from sklearn.preprocessing import StandardScaler # We will be using the inbuilt scaling functions sklearn provides\n",
    "import matplotlib.pyplot as plt # We will be using Matplotlib for our graphs\n",
    "from sklearn.model_selection import train_test_split # A library that can automatically perform data splitting for us\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score, classification_report, balanced_accuracy_score # Various classification metrics we may find useful\n",
    "\n",
    "# Below are a wide selection of tensorflow libraries we will need to construct our Neural networks.\n",
    "from tensorflow.keras.activations import sigmoid, linear, relu, softmax # Activation functions we will use\n",
    "from tensorflow.keras.models import Model, Sequential # Different mays of constructing models, we will primarily be covering the 'functional api' which uses `Model`\n",
    "from tensorflow.keras.optimizers import SGD # We will be using the SGD optimiser today, though there are other options you may want to explore (such as Adam)\n",
    "from tensorflow.keras.losses import MeanSquaredError, BinaryCrossentropy, CategoricalCrossentropy, SparseCategoricalCrossentropy  # We will be using TFs MSE loss function for regression and BinaryCross Entropy for classification.\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout # The layers we will be using to construct our network.\n",
    "from tensorflow.keras.regularizers import L1, L2 # Regularisation being used in model layers\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, Accuracy # Accuracy Metric for classification\n",
    "from tensorflow.keras.callbacks import EarlyStopping # Allows Early Stopping regularisation method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3nzN8a4kdjF"
   },
   "source": [
    "#1. Basic pipeline of implementing a neural network model in `tensorflow.keras` (Regression case).\n",
    "We can implement various neural networks using `tensorflow.keras`. First, we discuss multi-layer perceptron (fully connected neural network) as the easiest model before going into trying to construct more complicated models in the exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acMQ9sQc6K6_"
   },
   "source": [
    "## 1.1 Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0DeuTW57ENl"
   },
   "source": [
    "Load the house price data:\n",
    "\n",
    "To keep things straightforward and get straight to building the Neural Networks, we don't want to deal with data cleansing and EDA. For this reason, we will be take the now very familiar California House Price dataset (and later for classification the breast cancer dataset) as our examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ezYnBpE1tX4c"
   },
   "outputs": [],
   "source": [
    "# Load the house price dataset\n",
    "X_pd, y_pd = sklearn.datasets.fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "\n",
    "# Display the whole dataset\n",
    "XY_pd = pd.concat([X_pd, y_pd], axis=1)\n",
    "display(XY_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CxWsJnhtY73i"
   },
   "source": [
    "Data splitting:\n",
    "\n",
    "We first convert the data into `numpy.ndarray`, then apply the `sklearn.model_selection.train_test_split` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uSA1Y9KSso08"
   },
   "outputs": [],
   "source": [
    "# prepare NumPy ndarrays\n",
    "X_raw = X_pd.to_numpy()\n",
    "y = y_pd.to_numpy()\n",
    "\n",
    "# Split the data into training/test data\n",
    "# While we have 20640 pairs of a feature and target, we use 20% only for the test, not for training and validation.\n",
    "# `shuffle=True` for non-time series case. You should set `shuffle=False` to avoid future data being contaminated in the training data.\n",
    "X_nontest_raw, X_test_raw, y_nontest, y_test = train_test_split(X_raw, y, test_size=0.20, shuffle=True, random_state=0)\n",
    "X_train_raw, X_valid_raw, y_train, y_valid = train_test_split(X_nontest_raw, y_nontest, test_size=0.25, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQr4CLycb8Av"
   },
   "source": [
    "Pre-processing:\n",
    "\n",
    "Fit a `sklearn.preprocessing.StandardScaler` instance to the training data, then transpose the validation and test data by the instance.\n",
    "\n",
    "For advanced preprocessing operations for images and text (which we won't be covering in this module, but may be of interest for your MSc projects or in Applied Machine Learning next term), you can also use classes defined in the `tensorflow.keras.preprocessing` module ([see here](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lnnNNsbZX9iM"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw)\n",
    "X_train = scaler.transform(X_train_raw)\n",
    "X_valid = scaler.transform(X_valid_raw)\n",
    "X_test = scaler.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8rOq6K3amH0e"
   },
   "source": [
    "Confirm the shape of the feature matrix:\n",
    "\n",
    "While it is always a good idea to check the dimensions of your data, this is particularly important when defining a neural network in `tensorflow.keras` as we need to know the shape (dimension) of the input (feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tD9NKAQNmky8"
   },
   "outputs": [],
   "source": [
    "print('The shape of `X_train`:', X_train.shape)\n",
    "print('The shape of `X_valid`:', X_valid.shape)\n",
    "print('The shape of `X_test`:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9IiASbpm_ug"
   },
   "source": [
    "The above results show that, for example, we have 12384 data points in the training data, and the features of each data point is 8-dimensional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mpQNoXdj05c"
   },
   "source": [
    "## 1.2 Create a neural network model by composing `tensorflow.keras` layers.\n",
    "In the machine learning context, many of the models we have been spending a long time working with are defined as a parametrized function, so our task here is how we can achieve that for a Neural Network model.\n",
    "\n",
    "In `tensorflow.keras`, we define this parametrized function by composing neural network layers, each of which are themselves a Neural Network. Likewise, the graph structure of the neural network is defined by the composition of these layers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0lNLNel4YHX"
   },
   "source": [
    "### 1.2.1 Define neural network layers\n",
    "First, we create layer instances to be composed to define our neural network model. Specifically, we create instances of classes in the `tensorflow.keras.layers` module, specifying an activation function by taking a function in the `tensorflow.keras.activations` module as an `activation` argument in the initializer of the layer class.\n",
    "\n",
    "As an example, we create `tensorflow.keras.layers.Dense` instances (fully connected layers) in the cell below.\n",
    "\n",
    "The function defined by the `Dense` layer is as follows:\n",
    "$$\n",
    "{\\Vec{a}^{\\mathrm{out}}} = f (\\Vec{b} + {\\Vec{a}^{\\mathrm{in}}} \\Mat{W}),\n",
    "$$\n",
    "where\n",
    "\n",
    "- ${\\Vec{a}^{\\mathrm{in}}}$: the input row vector of the layer. We denote the dimensionality of the ${\\Vec{a}^{\\mathrm{in}}}$ by $n^{\\mathrm{in}}$.\n",
    "- ${\\Vec{a}^{\\mathrm{out}}}$: the output row vector of the layer. We denote the dimensionality of the ${\\Vec{a}^{\\mathrm{out}}}$ by $n^{\\mathrm{out}}$. We specify $n^{\\mathrm{out}}$ by the `units` parameter in the `Dense` class's initializer.\n",
    "- $\\Mat{W}$: a matrix of size $n^{\\mathrm{in}} \\times n^{\\mathrm{out}}$ called the \"kernel\" parameter of the layer. Each parameter of the matrix is a learnable parameter.\n",
    "- $\\Vec{b}$: an $n^{\\mathrm{out}}$-dimensional row vector called the \"bias\" parameter of the layer. Each parameter of the vector is a learnable parameter.\n",
    "- $f$: a scalar function called the \"activation function\" of the layer. Although $f$ is defined as a scalar function, it is applied to an $n^{\\mathrm{out}}$-dimensional vector elementwisely in the layer. Note that $f$ is fixed and not learnable, that is, invariant throughout the training process. The activation function $f$ is specified by the `activation` parameter in the `Dense` class's initializer.\n",
    "\n",
    "The activation function of the first and second layers we are going to use in this case is the sigmoid function given by `tensorflow.keras.activation.sigmoid` function, and that of the third layer is the identity function given by the `tensorflow.keras.activation.linear` function.\n",
    "\n",
    "The sigmoid function $\\varsigma$ is defined by\n",
    "$$\n",
    "\\varsigma (z) = \\frac{1}{1 + \\exp(- z)},\n",
    "$$\n",
    "and the identity function $\\mathop{\\mathrm{id}}$ is defined by\n",
    "$$\n",
    "\\mathop{\\mathrm{id}} (z) = z.\n",
    "$$\n",
    "\n",
    "For other layers, see [here](https://www.tensorflow.org/api_docs/python/tf/keras/layers) and for other activation functions, see [here](https://www.tensorflow.org/api_docs/python/tf/keras/activations). I would say that while traditionally the sigmoid function was widely used in dense layers, it has now been largely superseded as the 'default' choice by the Relu function, which is less computationally expensive and less likely to suffer issues with vanishing gradients.\n",
    "$$\n",
    "ReLU(z) = max(0,z)\n",
    "$$\n",
    "Note: For regression problems we should always use the identity function, but the other activations become more important for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f6dtgpBl3-v2"
   },
   "outputs": [],
   "source": [
    "# Define the first `Dense` layer.\n",
    "# The output dimension is 5, so we specify `units=5`.\n",
    "# The activation function is the sigmoid function, we specify `activation=sigmoid`.\n",
    "first_layer = Dense(units=5, activation=sigmoid)\n",
    "\n",
    "# Define the second `Dense` layer.\n",
    "# The output dimension is 5, so we specify `units=5`.\n",
    "# The activation function is the sigmoid function, we specify `activation=sigmoid`.\n",
    "second_layer = Dense(units=5, activation=sigmoid)\n",
    "\n",
    "# Define the third `Dense` layer.\n",
    "# The output dimension is 1, so we specify `units=1`.\n",
    "# The activation function is the identity function, we specify `activation=linear`.\n",
    "third_layer = Dense(units=1, activation=linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7Mc1KVm36w_"
   },
   "source": [
    "### 1.2.2 Compose layers.\n",
    "\n",
    "First, we create a `tensorflow.keras.layers.Input` instance as a **virtual input**, specifying the input shape as a `shape` argument in the initializer.\n",
    "Here, we omit the data size (the number of data points) from the argument. For example, our training data shape (`X_train.shape`) is `(12384, 8)` where the zeroth element indicates the data size and the first element is the number of features/columns, which will be our input. Hence we can manually specify `shape=(8, )` or extract the data using `shape=X_train.shape[1:]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cEucGaav7F51"
   },
   "outputs": [],
   "source": [
    "# Extract the number of features for our Networks input dimension\n",
    "features=X_train.shape[1:]\n",
    "# Define the \"virtual\" input\n",
    "input = Input(shape=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GwJmN3nB82_F"
   },
   "source": [
    "Note: For image processing problems, the input shape is often like `(data_size, width, height, channels)`, meaning we specify `shape=(width, height, channels)`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ra5rfRmH65E1"
   },
   "source": [
    "Once we create a `Input` instance, we \"call\" the first layer instance taking the `Input` instance as an argument.\n",
    "Subsequently, we call the second layer instance taking the output of the first layer as an argument. We continue this process for as many layers as we require.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PdfQhXVZ_WhN"
   },
   "outputs": [],
   "source": [
    "# Call the layers in a row to get a \"virtual\" output\n",
    "output = first_layer(input)\n",
    "output = second_layer(output)\n",
    "output = third_layer(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7DAJVoR-_oi"
   },
   "source": [
    "Once we have composed our final virtual output, we can create a `tf.keras.models.Model` instance, taking the virtual input (the `Input` instance) and virtual output (the return value of the last layer). This `Model` instance is the NN model that we have implemented, that can now be trained on data and used to make predictions like we have done with the `linear` model instances in previous weeks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eQW8yvhLDUSE"
   },
   "outputs": [],
   "source": [
    "# Define the neural network model.\n",
    "model = Model(inputs=[input], outputs=[output], name='multi_layer_perceptron')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2SF3FH2ADS1-"
   },
   "source": [
    "We can show the summary of our model by `summary` method of our `Model` instance. Which is always a good sanity check to ensure that our model seems to be functioning how we would expect.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dHeUtCy1D3qD"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MM4zH14ntVXf"
   },
   "source": [
    "Note: I am going to be using the TensorFlow functional API for creating Neural Networks in these tutorials. There are other methods, in particular the TensorFlow sequential API is very popular and probably a little easier to gasp from the start (See Appendix 1). The functional API has some advantages that allows for more complicated models to be constructed easily, but the sequential API is also fine for the majority of cases, and I do not mind which method you use to construct your NN's in your coursework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-ibBtNyS6C6"
   },
   "source": [
    "## 1.2.3 Example of the hypothesis function created by above model\n",
    "The above neural network represent the composition of the functions represented by the three `Dense` layers. Below is how we would write this NN model in functional form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMlFq-xaXomz"
   },
   "source": [
    "Let ${\\Vec{x}}^\\top$ be the input row vector. The output $\\eta$ of the neural network is given by\n",
    "$$\n",
    "{\\Vec{a}^{[1]}}^\\top = \\varsigma ({\\Vec{b}^{[1]}}^\\top + {\\Vec{x}}^\\top \\Mat{W}^{[1]}), \\\\\n",
    "{\\Vec{a}^{[2]}}^\\top = \\varsigma ({\\Vec{b}^{[2]}}^\\top + {\\Vec{a}^{[1]}}^\\top \\Mat{W}^{[2]}), \\\\\n",
    "\\eta = b^{[3]} + {\\Vec{a}^{[2]}}^\\top \\Vec{w}^{[3]}. \\\\\n",
    "$$\n",
    "where\n",
    "\n",
    "- $\\Mat{W}^{[1]}$: the \"kernel\" parameter of the first layer, a matrix of size $8 \\times 5$.\n",
    "- ${\\Vec{b}^{[1]}}^\\top$: the \"bias\" parameter of the first layer, an $5$-dimensional row vector.\n",
    "- $\\Mat{W}^{[2]}$: the \"kernel\" parameter of the second layer, a matrix of size $5 \\times 5$.\n",
    "- ${\\Vec{b}^{[2]}}^\\top$: the \"bias\" parameter of the second layer, an $5$-dimensional row vector.\n",
    "- $\\Vec{w}^{[3]}$: the \"kernel\" parameter of the third layer, a 5-dimensional row vector.\n",
    "- $b^{[3]}$: the \"bias\" parameter of the third layer, a scalar.\n",
    "\n",
    "We can also write the function in one line as follows:\n",
    "\n",
    "$$\n",
    "\\eta = b^{[3]} + \\varsigma ({\\Vec{b}^{[2]}}^\\top + \\varsigma ({\\Vec{b}^{[1]}}^\\top + {\\Vec{x}}^\\top \\Mat{W}^{[1]}) \\Mat{W}^{[2]}) \\Vec{w}^{[3]}\n",
    "$$\n",
    "\n",
    "Which really underlines just how the outputs of multi-layered neural networks are really just nested parameterised functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZjKXhJadPd2"
   },
   "source": [
    "## 1.3 Training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Md1Gc2oSuH7g"
   },
   "source": [
    "### 1.3.1 \"Compile\" the model: specifying a loss function and optimizer.\n",
    "Now we have defined a machine learning model as a set of parametrized functions, to train the model (or find the optimal parameters) we need to specify a loss function and an optimizer (an optimization algorithm).\n",
    "\n",
    "We can applly this by \"compiling\" the model. We execute this process by the `compile` method of the `Model` instance.\n",
    "\n",
    "In `tensorflow.keras`, we use an instance of a class in the `tensorflow.keras.losses` module as a loss function, and one in the `tensorflow.keras.optimizers` module as an optimizer. Specifically, we take a loss instance and optimizer instance as a `loss` and `optimizer` arguments of the `compile` method.\n",
    "\n",
    "In the cell below, we use a `tensorflow.keras.losses.MeanSquaredError` instance as a loss function, and a `tensorflow.keras.optimizers.SGD` (vanilla stochastic gradient descent) instance as an optimizer. For other loss functions, see [here](https://www.tensorflow.org/api_docs/python/tf/keras/losses) and for other optimizers, see  [here](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers). `tensorflow.keras.optimizers.Adam` is also often used and ha become a very widely used 'default' optimiser.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QvL_yY5TuHdO"
   },
   "outputs": [],
   "source": [
    "# Compile the model by specifying the optimization algorithm and the loss function.\n",
    "# Here, we specify the vanilla stochastic gradient descent\n",
    "# (a `tensorflow.keras.optimizers.SGD` instance) as an optimizer,\n",
    "# and mean squared error (a `MeanSquaredError` instance) as a loss function.\n",
    "sgd = SGD(learning_rate=0.01)\n",
    "mse = MeanSquaredError()\n",
    "model.compile(optimizer=sgd, loss=mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rbpelFHL1Hoa"
   },
   "source": [
    "### 1.3.2 \"Fit\" the model to the training data: Optimizing the parameters.\n",
    "Similar to a machine learning model instance in `sklearn`, we can train a neural network machine learning model defined by `tensorflow` using the `fit` method. The `fit` method apply the **forwardpropagation and backpropagation** to calculate the gradient vector.  \n",
    "\n",
    "Here, we specify the number of epochs (`epochs`) and the mini batch size (`batch_size`). The definitions of these terms are as follows:\n",
    "\n",
    "In the optimization by a stochastic gradient descent method, each update does not consider all the training data points at the same time.\n",
    "Instead, each update considers a subset of the dataset, called a **mini batch**.\n",
    "We first shuffle the training data points and divide them into multiple mini batches.\n",
    "Then, we update parameters based on the loss function and gradient vector for each mini batch.\n",
    "A pass through the mini batches that cover all the training data points once is called an **epoch**.\n",
    "Once we completed the updates based on all the mini batches in an epoch, we shuffle the training data points and divide them into new mini batches again, which begins a new epoch.\n",
    "\n",
    "For example, if we have 12384 training data points and the mini batch size is 1000, each epoch contains 13 mini batches, where each of the first 12 mini batches contains 1000 training data points and the last mini batch contains 384 data points. Hence, each epoch conducts 13 updates. If the number of epochs is 10, the algorithm updates the parameters 13x10=130 times.\n",
    "\n",
    "We can also input the validation data. If you input them, the loss function on the validation data will be displayed during the training. Note that the validation data does not affect the training results but can be used to identify overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7sPFD4AZ2cd2"
   },
   "outputs": [],
   "source": [
    "# Train the model.\n",
    "# `epochs` determines the number of epochs.\n",
    "# `batch_size` determines the batch_size.\n",
    "# We don't actually need to save the fit model to a new variable to train our model, but saving the output this ways lets us make a graph of the training and validation performance.\n",
    "history = model.fit(X_train, y_train, batch_size=1000, epochs=100, validation_data=(X_valid, y_valid))\n",
    "\n",
    "# Plot validation MSE, alwys nice to have plots to help us visualise things!\n",
    "plt.plot(history.history['loss'], label='MSE')\n",
    "plt.plot(history.history['val_loss'], label = 'val_MSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osrt3VAcClm9"
   },
   "source": [
    "You can see that each epoch contains 13 mini batches. `loss` and `val_loss` show the loss (the mean squared error) on the training data and the validation data, respectively. The losses decrease throughout the training and in this case our validation MSE is lower than our training, as both are still continuing to reduce there is no overfitting but we should consider training this model for longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89nqHpbwEl3f"
   },
   "source": [
    "## 1.4 Evaluation of the NN model\n",
    "We can evaluate the loss function on a new dataset by the `evaluate` method of the `Model` instance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r3HP3UGj3KHk"
   },
   "outputs": [],
   "source": [
    "mse_on_test = model.evaluate(X_test, y_test)\n",
    "print('The mean squared error on the test data:', mse_on_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4QPSmWM3L4G"
   },
   "source": [
    "This MSE looks to be in the same region as we saw for our validation data, so no evidence of overfitting here.\n",
    "We can make a prediction using the `predict` method just as we did in the `sklearn` cases. We can see how these predictions compare with our observed values and calculate the score function just as we did with out linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6TCZGXotEzpD"
   },
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Plot our predictions\n",
    "plt.scatter(X_test_raw[:,0], y_test,  color='black', label='y_true') # Observed y values\n",
    "plt.scatter(X_test_raw[:,0], y_test_pred, color='blue', label='y_pred') # predicted y values\n",
    "plt.xlabel('MedInc')\n",
    "plt.ylabel('house price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# The R2 score: 1 is perfect prediction\n",
    "print('R2 score: {:.4f}'.format(sklearn.metrics.r2_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJbjxLvf5bTn"
   },
   "source": [
    "## 1.5 Exercise 1\n",
    "So, our model above is performing okay, but honestly the Neural Network we've made here isn't that great and clearly needs more training if nothing else. Don't spend too long on this, but manually experiment with the model to see if you can make it more accurate (ideally without just training it for 1000's of steps!).\n",
    "\n",
    "Some things to try changing:\n",
    "*   More hidden layers\n",
    "*   More units in the hidden layers (remember that we generally want the same number of hidden units in each layer)\n",
    "*   Different activation functions in the hidden layers (say `relu` which is probably more appropriate for this type of problem, but you can try others, again these should generally be the same for each layer other than the output.)\n",
    "*   Different compiler option hyperparameters such as batch size, number of epochs, learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zph5YBTI68c6"
   },
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# Your code here\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXjBBvDuNfhG"
   },
   "source": [
    "# 2. Classification with Neural Networks\n",
    "\n",
    "Above we were using a Neural network to solve a regression problem. The process is very similar for classification problems, but there are some important distinctions we need to consider."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jo6jLRr-rDbm"
   },
   "source": [
    "## 2.1 Data preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QxbmR9d7N1e9"
   },
   "source": [
    "As with the regression case, all of this should be quite familiar, and in this case we will be using the breast cancer data for our classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J80TG1h2rDbn"
   },
   "outputs": [],
   "source": [
    "# Load the breast cancer dataset\n",
    "X_pd, y_pd = sklearn.datasets.load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "\n",
    "# Display the dataset\n",
    "Xy_pd = pd.concat([X_pd, y_pd], axis=1)\n",
    "display(Xy_pd)\n",
    "\n",
    "# prepare NumPy ndarrays\n",
    "X_raw = X_pd.to_numpy()\n",
    "#I'm going to just take a few columns, otherwise the problem is too easy!\n",
    "X_raw =  X_raw[:,0:2]\n",
    "y = y_pd.to_numpy()\n",
    "\n",
    "# Split the data into training/test data\n",
    "# While we have 569 pairs of a feature and target, we use 20% only for the test, not for training and validation.\n",
    "# `shuffle=True` for non-time series case. You should set `shuffle=False` to avoid future data being contaminated in the training data.\n",
    "X_nontest_raw, X_test_raw, y_nontest, y_test = train_test_split(X_raw, y, test_size=0.20, shuffle=True, random_state=0)\n",
    "X_train_raw, X_valid_raw, y_train, y_valid = train_test_split(X_nontest_raw, y_nontest, test_size=0.25, shuffle=True, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw)\n",
    "X_train = scaler.transform(X_train_raw)\n",
    "X_valid = scaler.transform(X_valid_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20bYJMrCrDbq"
   },
   "source": [
    "Confirm the shape of the feature matrix:\n",
    "\n",
    "While it is always a good idea to check the dimensions of your data, this is particularly important when defining a neural network in `tensorflow.keras` as we need to know the shape (dimension) of the input (feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07oo7bAbrDbq"
   },
   "outputs": [],
   "source": [
    "print('The shape of `X_train`:', X_train.shape)\n",
    "print('The shape of `X_valid`:', X_valid.shape)\n",
    "print('The shape of `X_test`:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fHfgYVaGrDbr"
   },
   "source": [
    "The above results show that, for example, we have 341 data points in the training data, and the features for each data point is 30-dimensional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4abWL_ar4Do"
   },
   "source": [
    "## 2.2 Create a neural network model.\n",
    "For classification, we define a discriminant function, which output a real value. This is because the loss function is defined on the output of the discriminant function, not of the hypothesis function, which outputs the target value.\n",
    "\n",
    "The activation function is very important for our output layer in classification. You can just use a `linear` identify function, but you will have to manually do something to this output to make it work for classification. Generally for binary classification `sigmoid` is uses (as it gives a value between 0 and 1) and for multi class classification `softmax` is used (as it gives a probability for each class).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QZew5ps5r4D7"
   },
   "outputs": [],
   "source": [
    "# Define the `Dense` layer.\n",
    "# The output dimension is 1, so we specify `units=1`.\n",
    "# lets use relu for the dense layer activation this time\n",
    "# The as we are performing binary classification, we specify `activation=sigmoid`.\n",
    "dense_layer_1 = Dense(units=10, activation=relu)\n",
    "output_layer = Dense(units=1, activation=sigmoid)\n",
    "\n",
    "# Define the \"virtual\" input\n",
    "input = Input(shape=X_train.shape[1:])\n",
    "\n",
    "# Define the \"virtual\" output\n",
    "output = dense_layer_1(input)\n",
    "output = output_layer(output)\n",
    "\n",
    "# Define the neural network model.\n",
    "model = Model(inputs=[input], outputs=[output], name='logistic_regression')\n",
    "\n",
    "# Output the summary of the model.\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mM4G7lsBQIp-"
   },
   "source": [
    "##2.3 Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tiygi6vbr4D8"
   },
   "source": [
    "### 2.3.1 \"Compile\" the model: specifying a loss function, metrics and an optimizer.\n",
    "Since logistic regression's loss function is the cross entropy, we create a `tensorflow.keras.losses.BinaryCrossentropy` instance and specify it as a `loss` argument of the `compile` method of the `Model` instance.\n",
    "The binary cross entropy loss is defined as follows:\n",
    "$$\n",
    "\\log (1 + \\exp(- y \\cdot \\eta)),\n",
    "$$\n",
    "where $y$ is the true target value converted to either 0 or 1 and $\\eta$ is the output of the discriminant function.\n",
    "\n",
    "Also, since we may also wish to observe evaluation metrics different from the loss function in classification, such as the accuracy score, we can specify metrics in the `compile` method. Specifically, we can input a list or tuple of instances of classes in the `tensorflow.keras.metrics` module. In the following cell, we create a `tensorflow.keras.metrics.BinaryAccuracy` instance and specify a list containing the `BinaryAccuracy` instance as a `metrics` argument of the `compile` method of the `Model` instance.\n",
    "\n",
    "For other metrics, see [here](https://www.tensorflow.org/api_docs/python/tf/keras/metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wam3qYVvr4D8"
   },
   "outputs": [],
   "source": [
    "# Compile the model by specifying the optimization algorithm and the loss function.\n",
    "# Here, we specify the vanilla stochastic gradient descent\n",
    "# (a `tensorflow.keras.optimizers.SGD` instance) as an optimizer,\n",
    "# and the binary cross entropy function (a `BinaryCrossentropy` instance)\n",
    "# as a loss function.\n",
    "\n",
    "# If we want to observe metrics other than the loss function we specified,\n",
    "# we can also specify the metrics in the `metrics` parameter\n",
    "# in the `compile` method.\n",
    "\n",
    "sgd = SGD(learning_rate=0.01)\n",
    "ce = BinaryCrossentropy()\n",
    "acc = BinaryAccuracy()\n",
    "model.compile(optimizer=sgd, loss=ce, metrics=[acc])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9erMZS0r4D8"
   },
   "source": [
    "### 2.3.2 \"Fit\" the model to the training data: Optimizing the parameters.\n",
    "In `tensorflow.keras`, we specify a class weight when we fit the model. Here, we have to specify the weight manually. Specifically, we create a Python dictionary such that keys are the class labels and values indicate the class weight. Revise Lecture 06 for the class weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7dg9Am5ir4D9"
   },
   "outputs": [],
   "source": [
    "# Train the model.\n",
    "# `epochs` determines the number of epochs.\n",
    "# `batch_size` determines the batch_size.\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=100, epochs=50, validation_data=(X_valid, y_valid))\n",
    "\n",
    "\n",
    "# Plot validation MSE, always nice to have plots to help us visualise things!\n",
    "plt.plot(history.history['binary_accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_binary_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gg5CZDj5r4D9"
   },
   "source": [
    "You can see that each epoch contains 4 mini batches. `loss` and `val_loss` show the loss function being used (the Binary Cross Entropy) on the training data and the validation data, but now we can also see our chosen accuracy metric for our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lC6e4w4JTo2O"
   },
   "source": [
    "## 2.4 Evaluation of the NN model\n",
    "we can calculate the loss and score at the same time using the `evaluate` method of the `Model` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvYZMse4UG9A"
   },
   "outputs": [],
   "source": [
    "ce_test, acc_test = model.evaluate(X_test, y_test)\n",
    "print('The cross entropy loss on the test data:', ce_test)\n",
    "print('The accuracy on the test data:', acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cuev1WBdUBaJ"
   },
   "source": [
    "This seems to be less accurate than our previous model outputs may lead us to expect, so possibly some overfitting is occuring, but we will come to that shortly.\n",
    "\n",
    "We can make a prediction using the `predict` method just as we did in the `sklearn` cases.\n",
    "\n",
    "Although our objective is classification, the `tensorflow.keras` model itself does not distinguish classification and regression. Hence, the outputs using the `predict` method is that of the discriminant function. For this reason, we will get a sequence of real values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_9DIGqaRVPGj"
   },
   "outputs": [],
   "source": [
    "y_test_logit = model.predict(X_test)\n",
    "print(y_test_logit[:10]) # just show you the first 10 to not spam you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMDd1Z4EW8Ho"
   },
   "source": [
    "We can convert the above results to binary prediction by thresholding at 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0pRhqlBAW8oC"
   },
   "outputs": [],
   "source": [
    "y_test_pred = (y_test_logit > 0.5).astype(int)\n",
    "print(y_test_pred[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R15RUGi0V0Aq"
   },
   "source": [
    "Finally, let's plot our outputs and look at our confusion matrix to further explore how well our model performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XIu86ZfGWWwW"
   },
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix(y_test, y_test_pred))\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.grid(False)\n",
    "\n",
    "acc_test = accuracy_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred, pos_label=1)\n",
    "print('The accuracy on the test data with the selected hyperparameter:', acc_test)\n",
    "print('The F1 score on the test data with the selected hyperparameter:', f1_test)\n",
    "pre_test = precision_score(y_test, y_test_pred, pos_label=1)\n",
    "print('Precision on test data:', pre_test)\n",
    "reca_test = recall_score(y_test, y_test_pred, pos_label=1)\n",
    "print('Recall on test data:', reca_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0H75GvVR6y_"
   },
   "source": [
    "## 2.5 Class imbalances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2k9RQoOSKSI"
   },
   "source": [
    "As covered in previous weeks, when performing classification, the number of instances in each class can have an impact on how well the model predicts each class.\n",
    "\n",
    "For the breast cancer dataset, the class imbalance isn't too bad, however we do have a slight imbalance that may be impacting our model. The first part of creating our model is the same:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0bhSlMMdR89S"
   },
   "outputs": [],
   "source": [
    "# Load the breast cancer dataset\n",
    "X_pd, y_pd = sklearn.datasets.load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "\n",
    "# prepare NumPy ndarrays\n",
    "X_raw = X_pd.to_numpy()\n",
    "X_raw =  X_raw[:,0:2]\n",
    "y = y_pd.to_numpy()\n",
    "\n",
    "# Split the data into training/test data\n",
    "# While we have 569 pairs of a feature and target, we use 20% only for the test, not for training and validation.\n",
    "# `shuffle=True` for non-time series case. You should set `shuffle=False` to avoid future data being contaminated in the training data.\n",
    "X_nontest_raw, X_test_raw, y_nontest, y_test = train_test_split(X_raw, y, test_size=0.20, shuffle=True, random_state=0)\n",
    "X_train_raw, X_valid_raw, y_train, y_valid = train_test_split(X_nontest_raw, y_nontest, test_size=0.25, shuffle=True, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw)\n",
    "X_train = scaler.transform(X_train_raw)\n",
    "X_valid = scaler.transform(X_valid_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n",
    "\n",
    "\n",
    "# Define the `Dense` layers.\n",
    "dense_layer_1 = Dense(units=10, activation=relu)\n",
    "output_layer = Dense(units=1, activation=sigmoid)\n",
    "\n",
    "# Define the \"virtual\" input\n",
    "input = Input(shape=X_train.shape[1:])\n",
    "\n",
    "# Define the \"virtual\" output\n",
    "output = dense_layer_1(input)\n",
    "output = output_layer(output)\n",
    "\n",
    "# Define the neural network model.\n",
    "model = Model(inputs=[input], outputs=[output], name='logistic_regression_balanced')\n",
    "\n",
    "# Output the summary of the model.\n",
    "model.summary()\n",
    "\n",
    "\n",
    "sgd = SGD(learning_rate=0.01)\n",
    "ce = BinaryCrossentropy()\n",
    "acc = BinaryAccuracy()\n",
    "model.compile(optimizer=sgd, loss=ce, metrics=[acc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_w5cwmlZ-Z5"
   },
   "source": [
    "What we change is at the 'fitting' stage - in `tensorflow.keras`, we can specify a class weight when we fit the model.\n",
    "\n",
    "Here, we have to specify the weight manually. Specifically, we create a Python dictionary such that keys are the class labels and values indicate the class weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kwukm8vqR9OO"
   },
   "outputs": [],
   "source": [
    "# Train the model.\n",
    "# `epochs` determines the number of epochs.\n",
    "# `batch_size` determines the batch_size.\n",
    "\n",
    "m = {}\n",
    "m[0] = np.sum((y_train == 0).astype(int)) # Count how many times `0` appears in the target matrix.\n",
    "m[1] = np.sum((y_train == 1).astype(int)) # Count how many times `1` appears in the target matrix.\n",
    "m_total = m[0] + m[1]\n",
    "class_weight = {0: m_total / (2.0 * m[0]), 1: m_total / (2.0 * m[1])}\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=100, epochs=50, validation_data=(X_valid, y_valid), class_weight=class_weight)\n",
    "\n",
    "# Plot validation MSE, alawys nice to have plots to help us visualise things!\n",
    "plt.plot(history.history['binary_accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_binary_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GIBNTgwc1OSn"
   },
   "source": [
    "As the `class_weight` is not supported in the `evaluate` method for tensorflow if you want to measure this metric we can use `sklearn` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gCSqorPX33sm"
   },
   "outputs": [],
   "source": [
    "y_test_logit = model.predict(X_test)\n",
    "y_test_pred = (y_test_logit > 0.5).astype(int)\n",
    "bacc = balanced_accuracy_score(y_test, y_test_pred)\n",
    "print('The balanced accuracy score on the test data:', bacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LpIA7MdGbHJi"
   },
   "source": [
    "But let's also use the same evaluation metrics we used for the unbalanced model. As we can see, by some metrics it performs better (precision), but by other worse. So as always with regression whether this makes for a better solution depends on what the model is being used for. Accounting for class weights can help, but don't automatically make your models better in all cases!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gj7NHp7ba4w3"
   },
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix(y_test, y_test_pred))\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.grid(False)\n",
    "\n",
    "acc_test = accuracy_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred, pos_label=1)\n",
    "print('The accuracy on the test data with the selected hyperparameter:', acc_test)\n",
    "print('The F1 score on the test data with the selected hyperparameter:', f1_test)\n",
    "pre_test = precision_score(y_test, y_test_pred, pos_label=1)\n",
    "print('Precision on test data:', pre_test)\n",
    "reca_test = recall_score(y_test, y_test_pred, pos_label=1)\n",
    "print('Recall on test data:', reca_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mc-FXmtWbgXm"
   },
   "source": [
    "##2.6 Exercise 2\n",
    "\n",
    "So far we have just been using a neural network with one layer and not many units. Add more layers, units and features to our NN and see if we can obtain even greater accuracy. I was able to get an f1 score of 0.97, can you beat me? (Though do remember, there is a stochastic element to the training of Neural Networks, so you may not always get the same accuracy running the same model multiple times from the start. Still, if your model is well constructed they should be comparable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xRIOIU8pbxUM"
   },
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# Your code here\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vSOpHKhLMCTY"
   },
   "source": [
    "## 2.7 Multi-class classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q5DUpVK-1ovA"
   },
   "source": [
    "Of course, as we learnt in previous weeks, we can also have classification problems with multiple classes. The implementation to solve these using Neural Networks isn't massively different, but as always has some differences we need to keep in mind.\n",
    "\n",
    "We will start by loading and scaling the Iris dataset as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tgu8Zw162Duf"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load the breast cancer dataset\n",
    "X_pd, y_pd = sklearn.datasets.load_iris(return_X_y=True, as_frame=True)\n",
    "\n",
    "# prepare NumPy ndarrays\n",
    "X_raw = X_pd.to_numpy()\n",
    "y = y_pd.to_numpy()\n",
    "\n",
    "# Split the data into training/test data\n",
    "X_nontest_raw, X_test_raw, y_nontest, y_test = train_test_split(X_raw, y, test_size=0.20, shuffle=True, random_state=0)\n",
    "X_train_raw, X_valid_raw, y_train, y_valid = train_test_split(X_nontest_raw, y_nontest, test_size=0.25, shuffle=True, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw)\n",
    "X_train = scaler.transform(X_train_raw)\n",
    "X_valid = scaler.transform(X_valid_raw)\n",
    "X_test = scaler.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VC_ETwEW2Uk4"
   },
   "source": [
    "Constructing the model architecture is mostly the same - but now we need to use the `softmax` activation function. For softmax to work properly we need to also change the output units to be the number of classes in our dataset (`3` in this case). This means the model will actually be outputting three target columns containing the probabilities for each class. We'll talk about how we deal with this in a moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ViXwUNNj2OXw"
   },
   "outputs": [],
   "source": [
    "# Define the `Dense` layer.\n",
    "dense_layer_1 = Dense(units=50, activation=relu)\n",
    "dense_layer_2 = Dense(units=50, activation=relu)\n",
    "out_layer = Dense(units=3, activation=softmax)\n",
    "\n",
    "# Define the \"virtual\" input\n",
    "input = Input(shape=X_raw.shape[1:])\n",
    "\n",
    "# Define the \"virtual\" output\n",
    "output = dense_layer_1(input)\n",
    "output = dense_layer_2(output)\n",
    "output = out_layer(output)\n",
    "\n",
    "# Define the neural network model.\n",
    "model = Model(inputs=[input], outputs=[output], name='Multi_class_Classification')\n",
    "\n",
    "# Output the summary of the model.\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6YfHFsdo3OqJ"
   },
   "source": [
    "When compiling our model, any optimiser still works, but we now need to think what loss functions and accuracy metrics to use.\n",
    "\n",
    "Because we are outputting columns we have a complication, as our dataset has the target in a single column. One option would be to one hot encode our target column, but tensorflow can also handle this mismatch is we use these `Sparse` loss/accuracy functions which know how to force the outputted data into the correct format for comparison with a single column target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-hWLY1S3OzQ"
   },
   "outputs": [],
   "source": [
    "# Import 'Sparse' losses/metrics\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "\n",
    "# Compile the model\n",
    "sgd = SGD(learning_rate=0.01)\n",
    "ce = SparseCategoricalCrossentropy()\n",
    "acc = SparseCategoricalAccuracy()\n",
    "model.compile(optimizer=sgd, loss=ce, metrics=[acc])\n",
    "\n",
    "# Train the model.\n",
    "history = model.fit(X_train, y_train, batch_size=20, epochs=100, validation_data=(X_valid, y_valid))\n",
    "\n",
    "# Plot validation MSE, always nice to have plots to help us visualise things!\n",
    "plt.plot(history.history['sparse_categorical_accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_sparse_categorical_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fyr1A5z4qw5"
   },
   "source": [
    "Now we can make predictions with our model. See below that our predictions still give three columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-B5PXEBvM3-D"
   },
   "outputs": [],
   "source": [
    "y_test_logit = model.predict(X_test)\n",
    "print(y_test_logit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUfP3xZT5B7p"
   },
   "source": [
    "We can use the `argmax` function to force this into a single column selecting the highest probability class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pd_vvZXf46Jz"
   },
   "outputs": [],
   "source": [
    "y_test_pred = np.argmax(y_test_logit, axis=1)\n",
    "print(y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gGDRmCKX5Q6w"
   },
   "source": [
    "This allows us to use this prediction in our confusion matrix and using our metrics - remember that other than accuracy they generally now need to be averaged ('macro' - for equal weighing of classes and 'weighted' to take into account class imbalance). to give us a good idea of the overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UBDIlbRRZgit"
   },
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix(y_test, y_test_pred))\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "acc_test = accuracy_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred, average='macro')\n",
    "print('The accuracy on the test data with the selected hyperparameter:', acc_test)\n",
    "print('The F1 score on the test data with the selected hyperparameter:', f1_test)\n",
    "pre_test = precision_score(y_test, y_test_pred, average='macro')\n",
    "print('Precision on test data:', pre_test)\n",
    "reca_test = recall_score(y_test, y_test_pred, average='macro')\n",
    "print('Recall on test data:', reca_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5rMsmtjsCOA"
   },
   "source": [
    "# 3. Parametric testing with Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBK0CYyasI_n"
   },
   "source": [
    "When constructing a Neural Network there are a number of things you may want to experiment with, including, but not limited to:\n",
    "\n",
    "1. Type of preprocessing used (Standardization vs Normalization, different encoding, missing data imputation, etc)  \n",
    "2. Changing the number of hidden units in the network\n",
    "3. Changing the number of layers in the network\n",
    "4. Using different activation functions in the hidden layers (Relu is a good default choice, but others may work better)\n",
    "5. Compiling the model with different optimizers (Adam is a safe choice, but there are other options)\n",
    "6. Changing the learning rates\n",
    "7. Train the model for more epochs\n",
    "8. Changing the batch sizes\n",
    "9. Trying different accuracy metrics\n",
    "10. Accounting for class imbalances\n",
    "\n",
    "When testing these, you need to make sure you go about it systematically and keep records of what improves or harms your model accuracy - don't just change things ad hoc and hope you eventually hit on the perfect model randomly!\n",
    "\n",
    "For some hyperparameters in particular (learning rate, regularisation strength, batch size, number of layers, number of units, etc) it is beneficial to tune these to obtain the best network.\n",
    "\n",
    "While we may want to experiment with some of these manually, in general the smart way to do things involves automating the process as much as possible. In past week's you have been shown how to do this for the regularisation strength, so let's do it again here for a Neural Network!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-lfliQEdHLlV"
   },
   "outputs": [],
   "source": [
    "# First we can define some functions to create our model then compile and train it\n",
    "# This should make our lives a bit easier and the code clearer when it comes to finding the parameters\n",
    "# This is a very simple one just for varying the number of hidden units, but using loops you could make something allowing much more complexity.\n",
    "def create_model(n_hidden=50):\n",
    "    dense_layer_1 = Dense(units=n_hidden, activation=relu)\n",
    "    dense_layer_2 = Dense(units=n_hidden, activation=relu)\n",
    "    out_layer = Dense(units=1, activation=sigmoid)\n",
    "    input=Input(shape=X_train.shape[1:])\n",
    "\n",
    "    output = dense_layer_1(input)\n",
    "    output = dense_layer_2(output)\n",
    "    output = out_layer(output)\n",
    "    model = Model(inputs=[input], outputs=[output], name='ParaTest')\n",
    "    return model\n",
    "\n",
    "def model_compile_and_training(X_train, y_train, X_valid, y_valid, learning_rate= 0.01, n_epochs= 10, batch_size=100):\n",
    "    model.compile(optimizer=SGD(learning_rate=learning_rate), loss=BinaryCrossentropy(), metrics=[BinaryAccuracy()])\n",
    "    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=n_epochs, validation_data=(X_valid, y_valid), verbose=0) # Verbose=0 suppresses the output\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZoNQbSCLenk"
   },
   "source": [
    "Now we can run the automated loop (make sure you give enough training time for a fair comparison - I have chosen a relatively small number of epochs just for this quick example, but I would usually expect you to do at least a few 100 to give all models a fair chance to converge):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OhyT0FQ2IZeY"
   },
   "outputs": [],
   "source": [
    "# Load the breast cancer dataset\n",
    "X_pd, y_pd = sklearn.datasets.load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "\n",
    "# Convert the target column vector `y_pd` into 2-dimensional array (a `pd.DataFrame` instance)\n",
    "y_pd = y_pd.to_frame()\n",
    "\n",
    "# prepare NumPy ndarrays\n",
    "X_raw = X_pd.to_numpy()\n",
    "y = y_pd.to_numpy()\n",
    "\n",
    "# Split the data into training/test data\n",
    "X_nontest_raw, X_test_raw, y_nontest, y_test = train_test_split(X_raw, y, test_size=0.20, shuffle=True, random_state=0)\n",
    "X_train_raw, X_valid_raw, y_train, y_valid = train_test_split(X_nontest_raw, y_nontest, test_size=0.25, shuffle=True, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw)\n",
    "X_train = scaler.transform(X_train_raw)\n",
    "X_valid = scaler.transform(X_valid_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n",
    "\n",
    "HUs = [10, 20, 50, 100]\n",
    "train_array = np.full([len(HUs)], np.nan)\n",
    "valid_array = np.full([len(HUs)], np.nan)\n",
    "f1_train_array = np.full([len(HUs)], np.nan)\n",
    "f1_valid_array = np.full([len(HUs)], np.nan)\n",
    "\n",
    "for HU_index, HU in enumerate(HUs):\n",
    "  # Run our two functions to create and compile the model\n",
    "  model = create_model(n_hidden=HU)\n",
    "  model_compile_and_training(X_train, y_train, X_valid, y_valid, learning_rate= 0.01, n_epochs= 50, batch_size=100)\n",
    "\n",
    "  y_pred_train = model.predict(X_train)\n",
    "  y_pred_train = (y_pred_train > 0.5).astype(int)\n",
    "\n",
    "  train_array[HU_index] = accuracy_score(y_train, y_pred_train)\n",
    "  f1_train_array[HU_index] = f1_score(y_train, y_pred_train, pos_label=1)\n",
    "\n",
    "  y_pred_valid = model.predict(X_valid)\n",
    "  y_pred_valid = (y_pred_valid > 0.5).astype(int)\n",
    "\n",
    "  valid_array[HU_index] = accuracy_score(y_valid, y_pred_valid)\n",
    "  f1_valid_array[HU_index] = f1_score(y_valid, y_pred_valid, pos_label=1)\n",
    "\n",
    "\n",
    "# Select our best performing C (biggest f1)\n",
    "best_HU_index = np.argmax(f1_valid_array)\n",
    "best_HU= HUs[best_HU_index]\n",
    "print('The best number of hidden units:', best_HU)\n",
    "\n",
    "# plot the results\n",
    "plt.figure()\n",
    "plt.plot(HUs, f1_train_array, '-x', label='training f1')\n",
    "plt.plot(HUs, f1_valid_array, '-x', label= 'val f1')\n",
    "plt.xlabel('Hidden Units')\n",
    "plt.ylabel('Final F1 score')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-l8wHWeRm7tG"
   },
   "source": [
    "## 3.1 Addressing Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsMGFJTxnACU"
   },
   "source": [
    "As explained in the lecture, Neural Networks are just as prone to overfitting as other complex models.\n",
    "\n",
    "There are various manual approaches you can take such as:\n",
    "*   Removing Neurons and/or layers from the model (lowering complexity)\n",
    "*   Obtaining more training data\n",
    "*   Removing unneeded features\n",
    "\n",
    "But as with our linear models, manually experimenting with these things can be quite slow. While simplifying needlessly complex models and data is never a bad thing, there are a selection of automatic techniques which are quick and easy to implement that should help with any overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UqvJvWdwomsg"
   },
   "source": [
    "###3.1.1 Regularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "00TOUPbDorx2"
   },
   "source": [
    "\n",
    "As we discussed in previous lectures, we need regularisation to make the optimization stable as well as to avoid overfitting which can be useful for both regression and classification models.\n",
    "\n",
    "You can integrate regularisation directly into your dense layers, and this can also apply for Regression problems where it performs the same purpose as it did in general models where it adds a term to the cost function that will encourage the model to minimise the magnitude of edge weights (parameters) being used by the model. We can again specify L1 (Lasso) regularisation and L2 (Ridge) regression. Of course, if you use regularisation you need to be careful with picking you hyperparameter $\\alpha$, otherwise you could either end up underfitting if it is too high and the regularisation will have no effect if it is too small.\n",
    "\n",
    "For other regularizers, see [here](https://www.tensorflow.org/api_docs/python/tf/keras/regularizers).\n",
    "\n",
    "See below for an example of the code you need to include in your network to add regularisation:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7MrtWD2rxOaR"
   },
   "outputs": [],
   "source": [
    "# Define the regularizer.\n",
    "alpha = 0.001\n",
    "#Pick one of the Regularisation methods\n",
    "kernel_regularizer = L1(l1=alpha) #Lasso\n",
    "kernel_regularizer = L2(l2=alpha) #Ridge\n",
    "layer = Dense(units=10, activation=relu, kernel_regularizer=kernel_regularizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WnXUmozjxvB4"
   },
   "source": [
    "###3.1.2 Dropout Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GG_JGo6QxzGH"
   },
   "source": [
    "In order to simulate training multiple models in parallel and combining them, adding dropout layers randomly turn off nodes in the network with every epoch to make the Network more robust to overfitting particular nodes/edges. The proportion of dropouts and even the number of dropout nodes are both other hyperparameters that need considering when constructing your model (if you decide to include dropout). A single dropout layer may not be enough in truly complicated networks!\n",
    "\n",
    "See below for an example of a basic model with a dropout layer added. Often you will have dropout layers to correspond with every dense layer, but as always in ML there are many different strategies used.\n",
    "\n",
    "Note: this is quite a simple network and having dropout nodes is probably a bit overkill, though adding dropout to your layers is usually a good thing as it should make the network more robust.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1TvEMp-DyXPt"
   },
   "outputs": [],
   "source": [
    "X_pd, y_pd = sklearn.datasets.fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "y_pd = y_pd.to_frame()\n",
    "\n",
    "X_raw = X_pd.to_numpy()\n",
    "X_raw=X_raw[0:1000,0:2]\n",
    "y = y_pd.to_numpy()\n",
    "y=y[0:1000]\n",
    "\n",
    "X_nontest_raw, X_test_raw, y_nontest, y_test = train_test_split(X_raw, y, test_size=0.20, shuffle=True, random_state=0)\n",
    "X_train_raw, X_valid_raw, y_train, y_valid = train_test_split(X_nontest_raw, y_nontest, test_size=0.25, shuffle=True, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw)\n",
    "X_train = scaler.transform(X_train_raw)\n",
    "X_valid = scaler.transform(X_valid_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n",
    "\n",
    "first_layer = Dense(units=128*4, activation=relu)\n",
    "##############################\n",
    "# Set proportion of nodes to deactivate with every training iteration (20% in this case)\n",
    "second_layer = Dropout(0.2)\n",
    "##############################\n",
    "third_layer = Dense(units=128*4, activation=relu)\n",
    "forth_layer = Dense(units=128*4, activation=relu)\n",
    "fifth_layer = Dense(units=128*4, activation=relu)\n",
    "out_layer = Dense(units=1, activation=linear)\n",
    "\n",
    "input = Input(shape=X_train.shape[1:])\n",
    "output = first_layer(input)\n",
    "output = second_layer(output)\n",
    "output = third_layer(output)\n",
    "output = forth_layer(output)\n",
    "output = fifth_layer(output)\n",
    "output = out_layer(output)\n",
    "\n",
    "# Define the neural network model.\n",
    "model = Model(inputs=[input], outputs=[output], name='Dropout')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jh4Pt8ZlyiR9"
   },
   "outputs": [],
   "source": [
    "# Compile the model by specifying the optimization algorithm and the loss function.\n",
    "sgd = SGD(learning_rate=0.01)\n",
    "mse = MeanSquaredError()\n",
    "model.compile(optimizer=sgd, loss=mse)\n",
    "\n",
    "# Train the model.\n",
    "history = model.fit(X_train, y_train, batch_size=1000, epochs=100, validation_data=(X_valid, y_valid), verbose=1)\n",
    "\n",
    "# Plot validation MSE, always nice to have plots to help us visualise things!\n",
    "plt.plot(history.history['loss'], label='MSE')\n",
    "plt.plot(history.history['val_loss'], label = 'val_MSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4sqqrx7_z0PZ"
   },
   "source": [
    "###3.1.3 Early Stopping\n",
    "\n",
    "Early stopping simply monitors the validation data, and if it identifies that the validation accuracy/error is deteriorating then it will stop training the model further. However, you do want to leave some leeway as fitting Neural Networks can be a bit stochastic, so you don't want to immediately stop the first time the validation loss increases. This tolerance is called the `patience` and is a hyperparamter that says how many iterations it will tolerate with a loss above the best observed value. You may need to experiment with so that you can hit the sweet spot of not overfitting but also not ending your training prematurely.\n",
    "\n",
    "This can simply be done by making a callback instance and defining this when fitting the model, there is an example on a simple model below (callback information in the second cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A-XoeoXO2Igx"
   },
   "outputs": [],
   "source": [
    "X_pd, y_pd = sklearn.datasets.fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "y_pd = y_pd.to_frame()\n",
    "\n",
    "X_raw = X_pd.to_numpy()\n",
    "X_raw=X_raw[0:500,0:2]\n",
    "y = y_pd.to_numpy()\n",
    "y=y[0:500]\n",
    "\n",
    "X_nontest_raw, X_test_raw, y_nontest, y_test = train_test_split(X_raw, y, test_size=0.20, shuffle=True, random_state=0)\n",
    "X_train_raw, X_valid_raw, y_train, y_valid = train_test_split(X_nontest_raw, y_nontest, test_size=0.25, shuffle=True, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw)\n",
    "X_train = scaler.transform(X_train_raw)\n",
    "X_valid = scaler.transform(X_valid_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n",
    "\n",
    "first_layer = Dense(units=128*4, activation=relu)\n",
    "second_layer = Dense(units=128*4, activation=relu)\n",
    "third_layer = Dense(units=128*4, activation=relu)\n",
    "forth_layer = Dense(units=128*4, activation=relu)\n",
    "fifth_layer = Dense(units=128*4, activation=relu)\n",
    "out_layer = Dense(units=1, activation=linear)\n",
    "\n",
    "input = Input(shape=X_train.shape[1:])\n",
    "output = first_layer(input)\n",
    "output = second_layer(output)\n",
    "output = third_layer(output)\n",
    "output = forth_layer(output)\n",
    "output = fifth_layer(output)\n",
    "output = out_layer(output)\n",
    "\n",
    "# Define the neural network model.\n",
    "model = Model(inputs=[input], outputs=[output], name='Early_Stop')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uU-wpfkY0fSn"
   },
   "outputs": [],
   "source": [
    "# Compile the model by specifying the optimization algorithm and the loss function.\n",
    "sgd = SGD(learning_rate=0.1)\n",
    "mse = MeanSquaredError()\n",
    "model.compile(optimizer=sgd, loss=mse)\n",
    "\n",
    "###################################################################################\n",
    "# Early Stopping\n",
    "# Choose what metric to monitor (validation accuracy a good metric for overfitting in regression)\n",
    "# Patience is how many iterations with a loss above the lowest observed value will be tolerated\n",
    "callback = EarlyStopping(monitor='val_loss', patience=3)\n",
    "####################################################################################\n",
    "\n",
    "# Train the model.\n",
    "history = model.fit(X_train, y_train, batch_size=1000, epochs=100, validation_data=(X_valid, y_valid), verbose=1, callbacks=[callback])\n",
    "\n",
    "# Plot validation MSE, always nice to have plots to help us visualise things!\n",
    "plt.plot(history.history['loss'], label='MSE')\n",
    "plt.plot(history.history['val_loss'], label = 'val_MSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jd2yHoch8h_J"
   },
   "source": [
    "##3.2 Continuing training\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rficDgA8sIY"
   },
   "source": [
    "One thing you may not have noticed is that you can continue training your model without having to start from scratch each time. You can do this simply by rerunning (you can change things like the `epoch` so you don't have to run it under exactly the same conditions):\n",
    "\n",
    "`history = model.fit(....)`\n",
    "\n",
    "which will take the existing model you have already trained and continue training from there. This can be useful if you think your model is nearly converged and you just want to run it for a little longer and/or you don't want to lose the time you spent training previously.\n",
    "\n",
    "Of course, you may not always want to do this, and you can 'reset' your model weights by rerunning the code that defines the model object:\n",
    "\n",
    "`model = Model(...)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZxoicUW4QUi"
   },
   "source": [
    "## 3.3 Saving your model\n",
    "\n",
    "Sometimes it can take a long time to train a model that uses big data or is very complex, so obviously you don't want to lose this progress, but one issue with using Colab is that it clears out your runtime every time you stop using it.\n",
    "\n",
    "For that reason, you may want to save the trained weights of your model so you can come back to it later and improve it or use it for making predictions on other data.\n",
    "\n",
    "If you are interested in learning more about this, I would direct you to [TensorFLow's tutorial on the topic.](https://www.tensorflow.org/tutorials/keras/save_and_load)\n",
    "\n",
    "I won't go into this in any further detail here, as it should not be an issue for your coursework or any of the tutorials. But I thought it would be useful to let you know this is an option in case it is relevant to you later in your MSC project or in your work.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZnqFNnq0Lsti"
   },
   "source": [
    "## 3.4 Exercise 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qg5KEknZL38B"
   },
   "source": [
    "Try using this rough framework to experiment with a few different parameters to optimise the breast cancer dataset\n",
    "\n",
    "\n",
    "1.   Try training the models for more epochs when calculating the regularisation weight.\n",
    "2.   Try altering the learning rate.\n",
    "3.   Try testing different number of hidden units.\n",
    "4.   Change the number of layers and try testing some of the above again, do you get different results?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DMbLQeypMvub"
   },
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# Your code here\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbmljoziPfzy"
   },
   "source": [
    "##3.5 Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GQwUtu1kPkMV"
   },
   "source": [
    "Use this parametric testing approach used above to try exploring the hyperparameters for your regression problem in **Exercise 1** to obtain the best model you can. I don't have a particular 'perfect' answer in mind here, what I want you to do is experiment with many of the aspects of a neural network discussed at the start of this section to see what the best model you can obtain is. This may involve multiple passes where you change the number of layers in the model (or their activation function, or some other fundamental change) and then you can work on optimising the hyperparameters.\n",
    "\n",
    "**Warning**: It may take some time for the parametric test to complete if you are running a model with many layers/units for potentially hundreds of epochs. It's impossible to train every permutation of model ever, all we can hope to do is advance things logically and systematically (e.g. pick an initial model structure, try tuning the hyperparameters on this model, once you have these hyperparameters you can experiment with changing the model layout. Then you may want to go back again and see if tuning the hyperparameters for this new model improves things). You also may want to try fitting a model on a subset of the data for speed, then try doing the final tunings on the full dataset once you have a model setup you are fairly happy with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EDBwVPZFSYzY"
   },
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# Your code here\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wh-mSNzAIBxg"
   },
   "source": [
    "##3.6 Exercise 5\n",
    "\n",
    "Try using everything we've learnt to find a model that provides good results on the Wine Dataset (`sklearn.datasets.load_wine()` - a multi class classification problem). This is quite an easy dataset, so I was able to get perfect accuracy on my test data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7nmext9nIX1f"
   },
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# Your code here\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FzrzumJVFoPF"
   },
   "source": [
    "#Appendix 1: Sequential Models (Bonus Exercise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-FACQRC2H5c_"
   },
   "source": [
    "In this tutorial we have been using the *functional* (`Model`) api for creating our neural networks ([see here for documentation](https://www.tensorflow.org/guide/keras/functional/)), but this isn't the only way we can create them.\n",
    "\n",
    "Another very common way of constructing Neural Networks is to use the `Sequential` model api ([see here for documentation](https://www.tensorflow.org/guide/keras/sequential_model)). Less common (in my experience), but you may also encounter how to make models using *subclassing*, which I won't cover here ([see here for documentation](https://www.tensorflow.org/guide/keras/custom_layers_and_models/)).\n",
    "\n",
    "I have chosen to use the `Model` api as I feel it offers you the best compromise between useability and being able to quite easily incorporate some more advanced functionality (such as transfer learning and multiple outputs).\n",
    "\n",
    "However, if you just want to create a linear Neural Network from scratch, the `Sequential` api is perfectly acceptable and quite intuitive to use, so feel free to use either method for your coursework.\n",
    "\n",
    "Below I have just implemented the first basic Neural Network we used at the start of the tutorial.\n",
    "\n",
    "**Bonus Exercise** This model is quite bad (certainly needs more training), see if you can get to grips with the sequential API and remake whatever your solution was for *Exercise 1*. You could also try remaking one of your classification models using this approach.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9Szb-v1G1xJ"
   },
   "outputs": [],
   "source": [
    "X_pd, y_pd = sklearn.datasets.fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "y_pd = y_pd.to_frame()\n",
    "\n",
    "X_raw = X_pd.to_numpy()\n",
    "y = y_pd.to_numpy()\n",
    "\n",
    "\n",
    "X_nontest_raw, X_test_raw, y_nontest, y_test = train_test_split(X_raw, y, test_size=0.20, shuffle=True, random_state=0)\n",
    "X_train_raw, X_valid_raw, y_train, y_valid = train_test_split(X_nontest_raw, y_nontest, test_size=0.25, shuffle=True, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw)\n",
    "X_train = scaler.transform(X_train_raw)\n",
    "X_valid = scaler.transform(X_valid_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n",
    "\n",
    "##################################################\n",
    "# Everything else in this should be the same as our initial example\n",
    "# Here we define our model first and add dense layers one at a time\n",
    "# While a bit simpler to understand, this approach is less flexible and doesn't allow us to do as much as the functional api.\n",
    "model = Sequential()\n",
    "# Note, we don't need to define an input layer, just specidy the input dimension for the first layer.\n",
    "model.add(Dense(5, input_dim=len(X_train[1]),activation='sigmoid'))\n",
    "model.add(Dense(5, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "##################################################\n",
    "\n",
    "# Should see that this is the same as the model we made earlier in the first example.\n",
    "model.summary()\n",
    "\n",
    "sgd = SGD(learning_rate=0.01)\n",
    "mse = MeanSquaredError()\n",
    "model.compile(optimizer=sgd, loss=mse)\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=1000, epochs=100, validation_data=(X_valid, y_valid), verbose=1)\n",
    "\n",
    "# Plot validation MSE, alwys nice to have plots to help us visualise things!\n",
    "plt.plot(history.history['loss'], label='MSE')\n",
    "plt.plot(history.history['val_loss'], label = 'val_MSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "mse_on_test = model.evaluate(X_test, y_test)\n",
    "print('The mean squared error on the test data:', mse_on_test)\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Plot our predictions\n",
    "plt.scatter(X_test_raw[:,0], y_test,  color='black', label='y_true') # Observed y values\n",
    "plt.scatter(X_test_raw[:,0], y_test_pred, color='blue', label='y_pred') # predicted y values\n",
    "plt.xlabel('MedInc')\n",
    "plt.ylabel('house price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# The R2 score: 1 is perfect prediction\n",
    "print('R2 score: {:.4f}'.format(sklearn.metrics.r2_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JA6lNDhDn5zD"
   },
   "source": [
    "#Appendix 2: Multiple outputs (Bonus Exercise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjce8ccYB7f_"
   },
   "source": [
    "I haven't mentioned this so far, and you have not been asked to do this for your coursework, but you should be aware that your models (not just Neural Networks) are capable of predicting multiple target outputs. Of course, you could just make two separate models to do this, but combining them certainly makes the coding workflow easier to follow.\n",
    "\n",
    "Just to show you how easy this is to do I have made a model predicting both the house value and the average rooms for the California Housing dataset. The functional api actually allows for complicated branching outputs that means you could have entirely separate layers being trained for each output and also means that (for example) a single model could perform regression and classification, among all sorts of other weird and wonderful complicated model constructions. But this becomes quite complicated and is far beyond the scope of what you need to know for this module, so I will leave researching that to you if your are interested.\n",
    "\n",
    "**Bonus Task** I have not optimised this model very much, so see if you can improve the performance for both targets!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nYb6sCJnC-YN"
   },
   "outputs": [],
   "source": [
    "# Here I am pulling the data into a single frame, then splitting it up into out two column target matrix and our reduced feature matrix (now missing the average rooms)\n",
    "# There may be a more elegant way to do this process.\n",
    "X_pd, y_pd = sklearn.datasets.fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "y_pd = y_pd.to_frame()\n",
    "Xy_pd = pd.concat([X_pd, y_pd], axis=1)\n",
    "y_pd=Xy_pd[['MedHouseVal','AveRooms']]\n",
    "X_pd=Xy_pd\n",
    "X_pd.drop(columns=['AveRooms','MedHouseVal'], inplace=True)\n",
    "X_raw = X_pd.to_numpy()\n",
    "y = y_pd.to_numpy()\n",
    "\n",
    "X_nontest_raw, X_test_raw, y_nontest, y_test = train_test_split(X_raw, y, test_size=0.20, shuffle=True, random_state=0)\n",
    "X_train_raw, X_valid_raw, y_train, y_valid = train_test_split(X_nontest_raw, y_nontest, test_size=0.25, shuffle=True, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw)\n",
    "X_train = scaler.transform(X_train_raw)\n",
    "X_valid = scaler.transform(X_valid_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n",
    "\n",
    "first_layer = Dense(units=10, activation=relu)\n",
    "second_layer = Dense(units=10, activation=relu)\n",
    "#############################################\n",
    "# This is the key step - here we are specifying two output units rather than 1 as we have been doing elsewhere.\n",
    "out_layer = Dense(units=2, activation=linear)\n",
    "#############################################\n",
    "\n",
    "input = Input(shape=X_train.shape[1:])\n",
    "output = first_layer(input)\n",
    "output = second_layer(output)\n",
    "output = out_layer(output)\n",
    "\n",
    "# Define the neural network model.\n",
    "model = Model(inputs=[input], outputs=[output], name='Appendix_2')\n",
    "model.summary()\n",
    "\n",
    "# Compile the model by specifying the optimization algorithm and the loss function.\n",
    "sgd = SGD(learning_rate=0.01)\n",
    "mse = MeanSquaredError()\n",
    "model.compile(optimizer=sgd, loss=mse)\n",
    "\n",
    "# Train the model.\n",
    "history = model.fit(X_train, y_train, batch_size=1000, epochs=100, validation_data=(X_valid, y_valid), verbose=1)\n",
    "\n",
    "# Plot validation MSE, alwys nice to have plots to help us visualise things!\n",
    "plt.plot(history.history['loss'], label='MSE')\n",
    "plt.plot(history.history['val_loss'], label = 'val_MSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "mse_on_test = model.evaluate(X_test, y_test)\n",
    "print('The mean squared error on the test data:', mse_on_test)\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Plot our predictions\n",
    "# MedInc\n",
    "plt.scatter(X_test_raw[:,0], y_test[:,0],  color='black', label='y_true') # Observed y values\n",
    "plt.scatter(X_test_raw[:,0], y_test_pred[:,0], color='blue', label='y_pred') # predicted y values\n",
    "plt.xlabel('MedInc')\n",
    "plt.ylabel('House Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# AveRooms\n",
    "plt.scatter(X_test_raw[:,0], y_test[:,1],  color='black', label='y_true') # Observed y values\n",
    "plt.scatter(X_test_raw[:,0], y_test_pred[:,1], color='blue', label='y_pred') # predicted y values\n",
    "plt.xlabel('MedInc')\n",
    "plt.ylabel('Average Rooms')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# The R2 score: 1 is perfect prediction\n",
    "print('R2 score (House Price): {:.4f}'.format(sklearn.metrics.r2_score(y_test[:,0], y_test_pred[:,0])))\n",
    "print('R2 score (Average Rooms): {:.4f}'.format(sklearn.metrics.r2_score(y_test[:,1], y_test_pred[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8C4G3lDNwo_9"
   },
   "source": [
    "#Appendix 3: Image inputs (Bonus Exercise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGe3AhlwCcsw"
   },
   "source": [
    "Next week we are going to be learning about Convolutional Neural Networks, which are widely used for creating Neural Networks that are good at identifying image features. However, normal Neural Networks are also capable of taking images as an input and classifying them with some accuracy. So, if you want to get a head start on your coursework you might want to have a look at this example of how you can load a dataset I have made of some images and classified them using a standard Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Ca9OFk4DNgX"
   },
   "source": [
    "First of all, I take the `T6-Dataset.zip` file I provided on moodle and upload it to your colab work space (don't unzip it first!). We can then use this `!unzip` command to extract these files inside colab, where we can start using them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2nPcgB84xr9N"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Define the directory name\n",
    "dir_name = 'T6-Dataset'\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(dir_name):\n",
    "    # Remove the directory\n",
    "    shutil.rmtree(dir_name)\n",
    "\n",
    "# Unzip the file\n",
    "!unzip {dir_name}.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7z0MrWPGDm75"
   },
   "source": [
    "And we can load the data like so (there are other methods such as using generators that I will touch on next week)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dzZysvRHDp5P"
   },
   "outputs": [],
   "source": [
    "# We need some extra packages to help us interact with the colab file system and load in the images\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Load metadata from the CSV file - this allows us to know what class each picture belongs to.\n",
    "metadata = pd.read_csv(f'{dir_name}/metadata.csv')\n",
    "\n",
    "# Define the directory where your images are located (in colab in our case)\n",
    "image_directory = dir_name\n",
    "\n",
    "# Define image size - this means we can rescale all our images to be the same size\n",
    "image_size = (100, 100)\n",
    "\n",
    "# Create lists to store image data and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Load and preprocess images\n",
    "for index, row in metadata.iterrows():\n",
    "    image_path = os.path.join(image_directory, row['image_name'])\n",
    "    image = load_img(image_path, target_size=image_size)\n",
    "    image_array = img_to_array(image) / 255.0  # Normalize pixel values to [0, 1]\n",
    "    images.append(image_array)\n",
    "    labels.append(row['class_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "knf5iL6YFKGa"
   },
   "source": [
    "And now let's visualise the dataset - this is a multi-class classification problem where we have three different shapes to identify!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vUW67hw7EZBY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the number of rows and columns for image visualization\n",
    "num_images_to_visualize = 20\n",
    "\n",
    "num_rows = 4\n",
    "num_columns = num_images_to_visualize // num_rows\n",
    "\n",
    "# Get a random subset of images from the validation set\n",
    "subset_indices = np.random.choice(20, num_images_to_visualize, replace=False)\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(num_rows, num_columns, figsize=(15, 7))\n",
    "\n",
    "# Loop through the subset of images\n",
    "for i, index in enumerate(subset_indices):\n",
    "    row = i // num_columns\n",
    "    col = i % num_columns\n",
    "\n",
    "    imd=(images[index]*255).astype(np.uint8)\n",
    "\n",
    "    # Plot the image\n",
    "    axes[row, col].imshow(imd)\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "    # Set the title with both true and predicted labels\n",
    "    title = f\"Label: {labels[index]}\\n\"\n",
    "    axes[row, col].set_title(title)\n",
    "\n",
    "# Adjust spacing and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRk8CwoWFfpe"
   },
   "source": [
    "Now let's try solving this with a Neural Network! Pay attention to my comments to understand what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T922t1o6asVV"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical # another way to `one hot encode` your target using tensorflow\n",
    "from tensorflow.keras.layers import Flatten # we need to use the 'flatten' layer to convert our images into a form our 'dense' layers can use.\n",
    "\n",
    "# Convert class labels to integers\n",
    "class_mapping = {'square': 0, 'circle': 1, 'triangle': 2}\n",
    "labels = [class_mapping[label] for label in labels]\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_non_test, X_test, y_non_test, y_test = train_test_split(images, labels, test_size=1/10, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_non_test, y_non_test, test_size=1/9, random_state=42)\n",
    "\n",
    "# Convert labels to one-hot encoded format (required for softmax - though we could also use 'sparse' loss/metrics)\n",
    "y_train_encoded = to_categorical(y_train, num_classes=3)\n",
    "y_valid_encoded = to_categorical(y_valid, num_classes=3)\n",
    "y_test_encoded = to_categorical(y_test, num_classes=3)\n",
    "\n",
    "# Define input layer - note this is actually a three channel colour image, we could probably convert to being grayscale for our case, but I will leave it this way for the example.\n",
    "input_layer = Input(shape=(100, 100, 3))\n",
    "\n",
    "# Define the model using the functional API\n",
    "x = Flatten()(input_layer) # we have to flatten our image for the dense layers - makes our data '1D'\n",
    "x = Dense(1000, activation=relu)(x)\n",
    "x = Dense(1000, activation=relu)(x)\n",
    "output_layer = Dense(3, activation=softmax)(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model using your training data\n",
    "history = model.fit(X_train, y_train_encoded, epochs=20, validation_data=(X_valid, y_valid_encoded))\n",
    "\n",
    "# Evaluate the model on the validation and test data\n",
    "validation_loss, validation_accuracy = model.evaluate(X_valid, y_valid_encoded)\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_encoded)\n",
    "\n",
    "print(f\"Validation loss: {validation_loss:.4f}\")\n",
    "print(f\"Validation accuracy: {validation_accuracy:.4f}\")\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5-qYIxlGz1n"
   },
   "source": [
    "Let's evaluate our network now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8mHtGNAN7z9H"
   },
   "outputs": [],
   "source": [
    "ce_test, acc_test = model.evaluate(X_test, y_test_encoded)\n",
    "print('The cross entropy loss on the test data:', ce_test)\n",
    "print('The accuracy on the test data:', acc_test)\n",
    "\n",
    "y_test_logit = model.predict(X_test)\n",
    "\n",
    "y_test_pred = np.argmax(y_test_logit, axis=1)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(np.array(y_test, dtype=int), y_test_pred))\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.grid(False)\n",
    "\n",
    "acc_test = accuracy_score(np.array(y_test, dtype=int), y_test_pred)\n",
    "f1_test = f1_score(np.array(y_test, dtype=int), y_test_pred, pos_label=1, average='macro')\n",
    "print('The accuracy on the test data with the selected hyperparameter:', acc_test)\n",
    "print('The F1 score on the test data with the selected hyperparameter:', f1_test)\n",
    "pre_test = precision_score(np.array(y_test, dtype=int), y_test_pred, pos_label=1, average='macro')\n",
    "print('Precision on validation data:', pre_test)\n",
    "reca_test = precision_score(np.array(y_test, dtype=int), y_test_pred, pos_label=1, average='macro')\n",
    "print('Recall on validation data:', reca_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N0GQ0XdVG54O"
   },
   "source": [
    "So not too great! Below I'm outputting some examples to see where our model is succeeding and failing.\n",
    "\n",
    "Bonus exercise: We're likely to reach an accuracy ceiling without going to Convolutional NN's, but you can try adding more nodes, layers and trying the other methods we've covered to see if you can get a better accuracy for this problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I1pQYhdE07wp"
   },
   "outputs": [],
   "source": [
    "# Define the number of rows and columns for image visualization\n",
    "num_images_to_visualize = 20\n",
    "\n",
    "num_rows = 4\n",
    "num_columns = num_images_to_visualize // num_rows\n",
    "\n",
    "# Get a random subset of images from the validation set\n",
    "subset_indices = np.random.choice(20, num_images_to_visualize, replace=False)\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(num_rows, num_columns, figsize=(15, 7))\n",
    "\n",
    "predicted_prob = model.predict(X_test)\n",
    "predicted_classes = np.argmax(predicted_prob, axis=1)\n",
    "\n",
    "predicted_classes_name = predicted_classes\n",
    "\n",
    "# Loop through the subset of images\n",
    "for i, index in enumerate(subset_indices):\n",
    "    row = i // num_columns\n",
    "    col = i % num_columns\n",
    "\n",
    "    imd=(X_test[index]*255).astype(np.uint8)\n",
    "\n",
    "    # Plot the image\n",
    "    axes[row, col].imshow(imd)\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "    # Set the title with both true and predicted labels\n",
    "    title = f\"True: {y_test[index]}\\nPredicted: {predicted_classes[index]}\"\n",
    "    axes[row, col].set_title(title)\n",
    "\n",
    "# Adjust spacing and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "COMP1801-ML(GPU)",
   "language": "python",
   "name": "comp1801-ml"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
